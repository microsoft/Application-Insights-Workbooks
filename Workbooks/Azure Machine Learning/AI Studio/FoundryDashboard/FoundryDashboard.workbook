{
    "version": "Notebook/1.0",
    "items": [
      {
        "type": 9,
        "content": {
          "version": "KqlParameterItem/1.0",
          "parameters": [
            {
              "id": "fe04b060-a336-4f44-882a-f73613825d3a",
              "version": "KqlParameterItem/1.0",
              "name": "TimeRange",
              "label": "Time Range",
              "type": 4,
              "isRequired": true,
              "typeSettings": {
                "selectableValues": [
                  {
                    "durationMs": 300000
                  },
                  {
                    "durationMs": 900000
                  },
                  {
                    "durationMs": 1800000
                  },
                  {
                    "durationMs": 3600000
                  },
                  {
                    "durationMs": 14400000
                  },
                  {
                    "durationMs": 43200000
                  },
                  {
                    "durationMs": 86400000
                  },
                  {
                    "durationMs": 172800000
                  },
                  {
                    "durationMs": 259200000
                  },
                  {
                    "durationMs": 604800000
                  },
                  {
                    "durationMs": 1209600000
                  },
                  {
                    "durationMs": 2419200000
                  },
                  {
                    "durationMs": 2592000000
                  },
                  {
                    "durationMs": 5184000000
                  },
                  {
                    "durationMs": 7776000000
                  }
                ],
                "allowCustom": true
              },
              "timeContext": {
                "durationMs": 604800000
              },
              "value": {
                "durationMs": 604800000
              },
              "key": "fe04b060-a336-4f44-882a-f73613825d3a"
            },
            {
              "id": "56e7925e-87ac-4da5-a28a-8d7a8c854195",
              "version": "KqlParameterItem/1.0",
              "name": "AzureAIProject",
              "label": "Azure AI Project",
              "type": 5,
              "isRequired": true,
              "isHiddenWhenLocked": true,
              "typeSettings": {
                "additionalResourceOptions": [
                  "value::1"
                ],
                "showDefault": false,
                "componentIdOnly": true
              },
              "defaultValue": "value::1",
              "key": "56e7925e-87ac-4da5-a28a-8d7a8c854195"
            },
            {
              "id": "910ca8e9-cacd-453a-8a2a-bafeb4463e06",
              "version": "KqlParameterItem/1.0",
              "name": "ApplicationInsights",
              "label": "Application Insights",
              "type": 5,
              "isRequired": true,
              "multiSelect": false,
              "query": "// this resource might be an ai resource OR an appinsights resource already\r\nresources | where id =~ \"{AzureAIProject}\"\r\n| extend appInsights = iff(\r\n// if the type alerady is appinsights, return it\r\ntype =~ \"microsoft.insights/components\", id,\r\n// if it wasn't look for the linked item inside properties\r\ntostring(properties.applicationInsights))\r\n| project appInsights, name, selected=1",
              "crossComponentResources": [
                "{AzureAIProject}"
              ],
              "isHiddenWhenLocked": true,
              "typeSettings": {
                "additionalResourceOptions": [
                  "value::1"
                ],
                "showDefault": false
              },
              "timeContextFromParameter": null,
              "defaultValue": "value::1",
              "queryType": 1,
              "resourceType": "microsoft.resourcegraph/resources",
              "key": "910ca8e9-cacd-453a-8a2a-bafeb4463e06"
            },
            {
              "id": "e7d3b1f7-46be-42a0-a230-bd956710205f",
              "version": "KqlParameterItem/1.0",
              "name": "Model",
              "label": "Model",
              "type": 2,
              "isRequired": false,
              "multiSelect": true,
              "quote": "'",
              "delimiter": ",",
              "query": "let get_model = (customDimensions: dynamic) {  iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\ndependencies\r\n| where isnotnull(customDimensions[\"gen_ai.system\"])\r\n| extend model = get_model(customDimensions)\r\n| where model != \"\"\r\n| distinct tostring(model)",
              "crossComponentResources": [
                "{ApplicationInsights}"
              ],
              "isHiddenWhenLocked": false,
              "typeSettings": {
                "additionalResourceOptions": [
                  "value::all"
                ],
                "selectAllValue": "*",
                "showDefault": false
              },
              "timeContext": {
                "durationMs": 0
              },
              "timeContextFromParameter": "TimeRange",
              "defaultValue": "value::all",
              "queryType": 0,
              "resourceType": "microsoft.insights/components"
            },
            {
              "id": "8d86fb4d-756c-4cd4-afdb-7ce2f8481600",
              "version": "KqlParameterItem/1.0",
              "name": "Application",
              "label": "Application",
              "type": 2,
              "multiSelect": true,
              "quote": "'",
              "delimiter": ",",
              "query": "dependencies\r\n| where isnotnull(customDimensions[\"gen_ai.system\"]) and isnotempty(customDimensions[\"gen_ai.response.model\"])\r\n| project application = cloud_RoleName\r\n| distinct tostring(application)\r\n",
              "crossComponentResources": [
                "{ApplicationInsights}"
              ],
              "isHiddenWhenLocked": false,
              "typeSettings": {
                "additionalResourceOptions": [
                  "value::all"
                ],
                "selectAllValue": "*",
                "showDefault": false
              },
              "timeContext": {
                "durationMs": 0
              },
              "timeContextFromParameter": "TimeRange",
              "defaultValue": "value::all",
              "queryType": 0,
              "resourceType": "microsoft.insights/components",
              "key": "8d86fb4d-756c-4cd4-afdb-7ce2f8481600"
            }
          ],
          "style": "pills",
          "queryType": 0,
          "resourceType": "microsoft.insights/components"
        },
        "name": "parameters",
        "id": "3d2881a4-b8e6-4cad-9da4-76f80cdd4687",
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "x": 0,
          "y": 0,
          "w": 24,
          "h": 2
        }
      },
      {
        "type": 1,
        "name": "Operational Metrics",
        "content": {
          "json": "",
          "title": "Operational Metrics",
          "showViewButton": false
        },
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "w": 24,
          "h": 1,
          "x": 0,
          "y": 2,
          "margin": "0",
          "padding": "0"
        },
        "id": "1d02e727-7504-44a2-b343-3ab4df211b00"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]); let model = dynamic([{Model}]); let start_time = {TimeRange:start}; let end_time = {TimeRange:end}; let period = end_time - start_time;\r\nlet get_model = (customDimensions: dynamic) {\r\n    iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"])\r\n};\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    customDimensions[\"gen_ai.system\"] != \"\" \r\n    and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\", \"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true \r\n    and (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model))\r\n    and ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet change_percent = (final: double, initial: double) {\r\n    // handle nulls and division-by-zero: return 0 if both zero/null, +inf if initial==0 and final>0\r\n    iff(isnull(initial) or initial == 0, iff(isnull(final) or final == 0, real(0), real(+inf)), (final - initial) / initial * 100)\r\n};\r\n// Base dataset\r\nlet base_data = dependencies\r\n    | where timestamp between (start_time .. end_time)\r\n    | where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n        (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n        ),\r\n        (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n        );\r\n// Get final_total_tokens using make-series\r\nlet make_series_result = deduped_data\r\n    | extend\r\n        input_tokens = todouble(customDimensions[\"gen_ai.usage.input_tokens\"]),\r\n        output_tokens = todouble(customDimensions[\"gen_ai.usage.output_tokens\"])\r\n    | make-series total_tokens = sum(coalesce(input_tokens, 0.0) + coalesce(output_tokens, 0.0))\r\n        on timestamp\r\n        from (start_time - period) to end_time step period\r\n    | extend\r\n        final_total_tokens = iff(isnull(total_tokens), 0.0, iff(array_length(total_tokens) >= 2, todouble(coalesce(total_tokens[1], 0.0)), iff(array_length(total_tokens) == 1, todouble(array_sum(total_tokens)), 0.0))),\r\n        metric = \"Total tokens\"\r\n    | project metric, final_total_tokens;\r\n// Get overall_percentage_change using bin/summarize\r\nlet bin_result = deduped_data\r\n    | extend\r\n        input_tokens = todouble(customDimensions[\"gen_ai.usage.input_tokens\"]),\r\n        output_tokens = todouble(customDimensions[\"gen_ai.usage.output_tokens\"])\r\n    | summarize total_tokens = sum(coalesce(input_tokens, 0.0) + coalesce(output_tokens, 0.0)) by bin(timestamp, period)\r\n    | order by timestamp asc\r\n    | extend metric = \"Total tokens\"\r\n    | summarize initial_total_tokens = min(total_tokens), final_total_tokens_bin = max(total_tokens) by metric\r\n    | extend overall_percentage_change = change_percent(final_total_tokens_bin, initial_total_tokens)\r\n    | project metric, overall_percentage_change;\r\nmake_series_result\r\n| join kind=inner bin_result on metric\r\n| project metric, final_total_tokens, overall_percentage_change",
          "size": 4,
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "tiles",
          "sortBy": [],
          "showViewButton": false,
          "showAnalytics": true,
          "tileSettings": {
            "titleContent": {
              "columnMatch": "metric",
              "formatter": 1
            },
            "leftContent": {
              "columnMatch": "final_total_tokens",
              "formatter": 12,
              "formatOptions": {
                "palette": "none"
              },
              "numberFormat": {
                "unit": 17,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "rightContent": {
              "columnMatch": "completion_tokens",
              "formatter": 1
            },
            "secondaryContent": {
              "columnMatch": "overall_percentage_change",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "colors",
                "thresholdsGrid": [
                  {
                    "operator": ">",
                    "thresholdValue": "0",
                    "representation": "green",
                    "text": "{0}{1} increase over time range"
                  },
                  {
                    "operator": "<",
                    "thresholdValue": "0",
                    "representation": "red",
                    "text": "{0}{1} decrease over time range"
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "gray",
                    "text": "No change"
                  }
                ],
                "showAsTag": true
              },
              "numberFormat": {
                "unit": 1,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "showBorder": true,
            "size": "full",
            "styleSettings": {
              "borderStyle": "rounded",
              "backgroundColor": "colorGray100"
            }
          }
        },
        "customWidth": "25",
        "name": "tokens tile",
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "x": 0,
          "y": 3,
          "w": 6,
          "h": 3,
          "padding": "0"
        },
        "id": "bc649845-2d64-4587-b9b3-3b4a6ffe217d"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);let start_time = {TimeRange:start}; let end_time = {TimeRange:end}; let period = end_time - start_time;\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet change_percent = (final: double, initial: double) { iff(initial == 0, iff(final == 0, real(0), real(+inf)), (final - initial) / initial * 100) };\r\n// Base dataset\r\nlet base_data = dependencies\r\n| where timestamp between ((start_time - period) .. end_time)\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n    ),\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n    );\r\ndeduped_data\r\n| where timestamp between ((start_time - period) .. end_time) // need two periods to compare \r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| where success == true // duration of unsuccessful calls is not representative\r\n| make-series kind=nonempty avg_duration = avg(duration) on timestamp from (start_time - period) to end_time step period\r\n| project final_duration = todouble(avg_duration[1]), initial_duration = todouble(avg_duration[0])\r\n| project metric = \"Average inference call duration\", final_duration, overall_percentage_change = change_percent(final_duration, initial_duration)\r\n",
          "size": 4,
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "tiles",
          "showViewButton": false,
          "showAnalytics": true,
          "tileSettings": {
            "titleContent": {
              "columnMatch": "metric",
              "formatter": 1
            },
            "leftContent": {
              "columnMatch": "final_duration",
              "formatter": 12,
              "formatOptions": {
                "palette": "none"
              },
              "numberFormat": {
                "unit": 23,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "secondaryContent": {
              "columnMatch": "overall_percentage_change",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "colors",
                "thresholdsGrid": [
                  {
                    "operator": ">",
                    "thresholdValue": "0",
                    "representation": "red",
                    "text": "{0}{1} increase over time range"
                  },
                  {
                    "operator": "<",
                    "thresholdValue": "0",
                    "representation": "green",
                    "text": "{0}{1} decrease over time range"
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "gray",
                    "text": "No change"
                  }
                ],
                "showAsTag": true
              },
              "numberFormat": {
                "unit": 1,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "showBorder": true,
            "size": "full",
            "styleSettings": {
              "borderStyle": "rounded",
              "backgroundColor": "colorGray100"
            }
          }
        },
        "customWidth": "25",
        "name": "latency tile",
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "x": 6,
          "y": 3,
          "w": 6,
          "h": 3,
          "padding": "0"
        },
        "id": "14eb89eb-829f-4e94-8c70-f86d79af32a2"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);let start_time = {TimeRange:start}; let end_time = {TimeRange:end}; let period = end_time - start_time;\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet change_percent = (final: double, initial: double) { iff(initial == 0, iff(final == 0, real(0), real(+inf)), (final - initial) / initial * 100) };\r\n// Base dataset\r\nlet base_data = dependencies\r\n| where timestamp between ((start_time - period) .. end_time)\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n    ),\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n    );\r\ndeduped_data\r\n| where timestamp between ((start_time - period) .. end_time) // need two periods to compare \r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| make-series kind=nonempty total_inference_calls = count() on timestamp from (start_time - period) to end_time step period\r\n| project final_calls = toint(total_inference_calls[1]), initial_calls = toint(total_inference_calls[0])\r\n| project metric = \"Total inference calls\", final_calls, overall_percentage_change=change_percent(final_calls, initial_calls)",
          "size": 4,
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "showViewButton": false,
          "showAnalytics": true,
          "visualization": "tiles",
          "tileSettings": {
            "titleContent": {
              "columnMatch": "metric",
              "formatter": 1
            },
            "leftContent": {
              "columnMatch": "final_calls",
              "formatter": 12,
              "formatOptions": {
                "palette": "none"
              },
              "numberFormat": {
                "unit": 17,
                "options": {
                  "style": "decimal"
                }
              }
            },
            "rightContent": {
              "columnMatch": "completion_tokens",
              "formatter": 1
            },
            "secondaryContent": {
              "columnMatch": "overall_percentage_change",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "colors",
                "thresholdsGrid": [
                  {
                    "operator": ">",
                    "thresholdValue": "0",
                    "representation": "green",
                    "text": "{0}{1} increase over time range"
                  },
                  {
                    "operator": "<",
                    "thresholdValue": "0",
                    "representation": "red",
                    "text": "{0}{1} decrease over time range"
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "gray",
                    "text": "No change"
                  }
                ],
                "showAsTag": true
              },
              "numberFormat": {
                "unit": 1,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "showBorder": true,
            "size": "full",
            "styleSettings": {
              "borderStyle": "rounded",
              "backgroundColor": "colorGray100"
            }
          }
        },
        "customWidth": "25",
        "name": "requests tile",
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "x": 12,
          "y": 3,
          "w": 6,
          "h": 3,
          "padding": "0"
        },
        "id": "b3d9a2a8-4dbf-40e2-afb3-b19e9f92565c"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);let start_time = {TimeRange:start}; let end_time = {TimeRange:end}; let period = end_time - start_time;\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet change_percent = (final: double, initial: double) { iff(initial == 0, iff(final == 0, real(0), real(+inf)), (final - initial) / initial * 100) };\r\n// Base dataset\r\nlet base_data = dependencies\r\n| where timestamp between ((start_time - period) .. end_time)\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n    ),\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n    );\r\ndeduped_data\r\n| where timestamp between ((start_time - period) .. end_time) // need two periods to compare \r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| make-series kind=nonempty error_ratio = todouble(countif(success == False)) / count()  on timestamp from (start_time - period) to end_time step period\r\n| project final_ratio = todouble(error_ratio[1]), initial_ratio = todouble(error_ratio[0])\r\n| project metric = \"Error rate\", final_ratio, overall_percentage_change = change_percent(final_ratio, initial_ratio)",
          "size": 4,
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "showViewButton": false,
          "showAnalytics": true,
          "visualization": "tiles",
          "tileSettings": {
            "titleContent": {
              "columnMatch": "metric",
              "formatter": 1
            },
            "leftContent": {
              "columnMatch": "final_ratio",
              "formatter": 12,
              "formatOptions": {
                "palette": "none"
              },
              "numberFormat": {
                "unit": 0,
                "options": {
                  "style": "percent",
                  "maximumFractionDigits": 1
                }
              }
            },
            "secondaryContent": {
              "columnMatch": "overall_percentage_change",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "colors",
                "thresholdsGrid": [
                  {
                    "operator": ">",
                    "thresholdValue": "0",
                    "representation": "red",
                    "text": "{0}{1} increase over time range"
                  },
                  {
                    "operator": "<",
                    "thresholdValue": "0",
                    "representation": "green",
                    "text": "{0}{1} decrease over time range"
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "gray",
                    "text": "No change"
                  }
                ],
                "showAsTag": true
              },
              "numberFormat": {
                "unit": 1,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "showBorder": true,
            "size": "full",
            "styleSettings": {
              "borderStyle": "rounded",
              "backgroundColor": "colorGray100"
            }
          }
        },
        "customWidth": "25",
        "name": "errors tile",
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "x": 18,
          "y": 3,
          "w": 6,
          "h": 3,
          "padding": "0"
        },
        "id": "0d068a98-a4ab-49e9-97bf-26d0fb026c8d"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);let start_time = {TimeRange:start}; let end_time = {TimeRange:end}; let period = end_time - start_time;\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and filter_model_and_app(customDimensions, app_name) == true\r\n};\r\nlet change_percent = (final: double, initial: double) { iff(initial == 0, iff(final == 0, real(0), real(+inf)), (final - initial) / initial * 100) };\r\nlet get_event_name = (customDimensions: dynamic, message: string) { iff(customDimensions[\"event.name\"] == \"\", message, customDimensions[\"event.name\"]) };\r\nlet get_evaluator_name = (customDimensions: dynamic, event_name: string) { iff(customDimensions[\"gen_ai.evaluator.name\"] == \"\", split(event_name, \".\")[2], tostring(customDimensions[\"gen_ai.evaluator.name\"])) };\r\nlet get_response_id = (customDimensions: dynamic) { \r\n    iff(\r\n    customDimensions[\"gen_ai.response.id\"] == \"\", \r\n    iff(customDimensions[\"gen_ai.thread.run.id\"] == \"\", \"\", strcat(tostring(customDimensions[\"gen_ai.thread.id\"]), \"/\", tostring(customDimensions[\"gen_ai.thread.run.id\"]))),\r\n    tostring(customDimensions[\"gen_ai.response.id\"])\r\n)\r\n}; \r\n// Deduplicate get_thread_run operations\r\nlet inference_calls =\r\n    union\r\n    (\r\n        dependencies\r\n        | where timestamp between ((start_time - period) .. end_time)\r\n        | where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n        | project response_id=get_response_id(customDimensions), model=tostring(get_model(customDimensions))\r\n    ),\r\n    (\r\n        dependencies\r\n        | where timestamp between ((start_time - period) .. end_time)\r\n        | where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n        | project response_id=get_response_id(customDimensions), model=tostring(get_model(customDimensions))\r\n    );\r\nlet evals = traces\r\n| where timestamp between ((start_time - period) .. end_time)\r\n| where filter_model_and_app(customDimensions, cloud_RoleName)\r\n| extend event_name = get_event_name(customDimensions, message)\r\n| where event_name startswith \"gen_ai.evaluation\"\r\n| extend evaluator_name = get_evaluator_name(customDimensions, event_name), score = todouble(customDimensions[\"gen_ai.evaluation.score\"]), response_id=get_response_id(customDimensions);\r\nevals \r\n| join kind=leftouter inference_calls on response_id\r\n| project response_id, model, score, evaluator_name, timestamp\r\n| summarize score=avg(score) by evaluator_name, bin (timestamp, {TimeRange:grain})\r\n| make-series score=avg(score) on timestamp from (start_time - period) to end_time step period by evaluator_name\r\n| extend final_score = todouble(score[1]), initial_score = todouble(score[0])\r\n| project final_score, initial_score, evaluator_name, overall_percentage_change = change_percent(final_score, initial_score)\r\n| order by evaluator_name\r\n",
          "size": 4,
          "noDataMessage": "The query returned no results. Note that you must instrument client application with distributed tracing to enable filtering by Application and Model. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "queryType": 0,
          "showAnalytics": true,
          "showViewButton": false,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "tiles",
          "tileSettings": {
            "titleContent": {
              "columnMatch": "evaluator_name",
              "formatter": 1
            },
            "leftContent": {
              "columnMatch": "final_score",
              "formatter": 12,
              "formatOptions": {
                "palette": "none"
              },
              "numberFormat": {
                "unit": 0,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "secondaryContent": {
              "columnMatch": "overall_percentage_change",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "colors",
                "thresholdsGrid": [
                  {
                    "operator": ">",
                    "thresholdValue": "0",
                    "representation": "green",
                    "text": "{0}{1} increase over time range"
                  },
                  {
                    "operator": "<",
                    "thresholdValue": "0",
                    "representation": "red",
                    "text": "{0}{1} decrease over time range"
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "gray",
                    "text": "No change"
                  }
                ],
                "showAsTag": true
              },
              "numberFormat": {
                "unit": 1,
                "options": {
                  "style": "decimal",
                  "maximumFractionDigits": 1
                }
              }
            },
            "showBorder": true,
            "size": "auto",
            "styleSettings": {
              "borderStyle": "rounded",
              "backgroundColor": "colorGray100",
              "layout": "grid"
            }
          },
          "title": "Evaluation Metrics ({$rowCount})"
        },
        "name": "evaluation metrics query tiles",
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "x": 0,
          "y": 6,
          "w": 24,
          "h": 3,
          "margin": "0",
          "padding": "0"
        },
        "id": "89d62328-30bf-4ad3-aae6-68be74e90132"
      },
      {
        "type": 1,
        "name": "Trendlines",
        "content": {
          "json": "",
          "showViewButton": false,
          "title": "Trendlines"
        },
        "styleSettings": {
          "showBorder": false,
          "borderStyle": "light rounded",
          "backgroundColor": "body",
          "w": 24,
          "h": 1,
          "x": 0,
          "y": 9,
          "margin": "0",
          "padding": "0"
        },
        "id": "d44bf433-eb82-41a0-b01d-49f9f2e6f68e"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\", \"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\n// Base dataset\r\nlet base_data = dependencies\r\n    | where timestamp {TimeRange}\r\n    | where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n        (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n        ),\r\n        (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n        );\r\ndeduped_data\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| summarize \r\n    Prompt_Tokens = sum(toint(customDimensions[\"gen_ai.usage.input_tokens\"])),\r\n    Completion_Tokens = sum(toint(customDimensions[\"gen_ai.usage.output_tokens\"])),\r\n    Total_Tokens = sum(toint(customDimensions[\"gen_ai.usage.input_tokens\"]) + toint(customDimensions[\"gen_ai.usage.output_tokens\"]))\r\n    by bin(timestamp, {TimeRange:grain})",
          "size": 0,
          "showAnnotations": true,
          "title": "Token usage",
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "linechart",
          "chartSettings": {
            "showMetrics": false,
            "showLegend": true,
            "seriesLabelSettings": [
              {
                "seriesName": "Prompt_Tokens",
                "label": "Input"
              },
              {
                "seriesName": "Completion_Tokens",
                "label": "Output"
              },
              {
                "seriesName": "Total_Tokens",
                "label": "Total"
              }
            ],
            "showDataPoints": true,
            "simpleLegendSettings": {
              "position": "bottom"
            },
            "xSettings": {
              "label": "Time"
            },
            "ySettings": {
              "label": "Token usage"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "id": "5dd92ecb-030a-496d-bd61-c8dedff06913",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 0,
          "y": 10,
          "w": 24,
          "h": 6
        }
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\n// Base dataset\r\nlet base_data = dependencies\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n    ),\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n    );\r\ndeduped_data\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| summarize inference_calls_count = count() by success, bin (timestamp,{TimeRange:grain})\r\n| project  inference_calls_count, success,timestamp",
          "size": 1,
          "showAnnotations": true,
          "title": "Total inference calls",
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "linechart",
          "chartSettings": {
            "showMetrics": false,
            "showLegend": true,
            "seriesLabelSettings": [
              {
                "seriesName": "True",
                "label": "Successful",
                "color": "greenDark"
              },
              {
                "seriesName": "False",
                "label": "Errors",
                "color": "red"
              }
            ],
            "simpleLegendSettings": {
              "position": "bottom"
            },
            "xSettings": {
              "label": "Time"
            },
            "ySettings": {
              "label": "Total inference calls"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "customWidth": "33.3",
        "name": "query - 1",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 0,
          "y": 16,
          "w": 8,
          "h": 6
        },
        "id": "6beefe53-1b57-4d1e-be93-70a4590a0cde"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\n// Base dataset\r\nlet base_data = dependencies\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n    ),\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n    );\r\ndeduped_data\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| where success == true // duration of unsuccessful calls is not representative\r\n| summarize p95=percentile(duration, 95), p50=percentile(duration, 50) by bin(timestamp, {TimeRange:grain})\r\n| project p95, p50, timestamp",
          "size": 1,
          "aggregation": 3,
          "showAnnotations": true,
          "title": "Inference call duration",
          "color": "lightBlue",
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "linechart",
          "chartSettings": {
            "ySettings": {
              "numberFormatSettings": {
                "unit": 23,
                "options": {
                  "style": "decimal",
                  "useGrouping": true,
                  "maximumFractionDigits": 0
                }
              },
              "label": "Inference call duration"
            },
            "showMetrics": false,
            "showLegend": true,
            "seriesLabelSettings": [
              {
                "seriesName": "p95",
                "label": "P95",
                "color": "greenDark"
              },
              {
                "seriesName": "p50",
                "label": "P50",
                "color": "lightGreen"
              }
            ],
            "simpleLegendSettings": {
              "position": "bottom"
            },
            "showDataPoints": true,
            "xSettings": {
              "label": "Time"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "customWidth": "33.3",
        "name": "query - 2",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 8,
          "y": 16,
          "w": 8,
          "h": 6
        },
        "id": "1c14d45e-cca7-4a39-a08d-fd8aed64ee09"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);\r\nlet get_model = (customDimensions: dynamic) { iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n    // this filters out non-genai calls/non-inference calls like create_agent\r\n    customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n    is_inference_call(customDimensions) == true and \r\n    (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n    ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\n// Base dataset\r\nlet base_data = dependencies\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true;\r\n// Dedup only for get_thread_run\r\nlet deduped_data =\r\n    union\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n    ),\r\n    (\r\n        base_data\r\n        | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n        | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n    );\r\ndeduped_data\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| summarize request_count = count() by success",
          "size": 1,
          "title": "Inference call status",
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "piechart",
          "chartSettings": {
            "showMetrics": false,
            "showLegend": true,
            "seriesLabelSettings": [
              {
                "seriesName": "True",
                "label": "Success",
                "color": "greenDark"
              },
              {
                "seriesName": "False",
                "label": "Error",
                "color": "red"
              }
            ],
            "simpleLegendSettings": {
              "position": "bottom"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "customWidth": "33.3",
        "name": "query - 3",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 16,
          "y": 16,
          "w": 8,
          "h": 6
        },
        "id": "8ddd5a7f-b5dc-4cb8-ab49-8583204a6d76"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);\r\nlet get_model = (customDimensions: dynamic) {  iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n   // this filters out non-genai calls/non-inference calls like create_agent\r\n  customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n  (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n  ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n  is_inference_call(customDimensions) == true and filter_model_and_app(customDimensions, app_name) == true\r\n};\r\nlet change_percent = (final: double, initial: double) {iff(initial == 0, iff(final == 0, real(0), real(+inf)), (final-initial) / initial * 100)};\r\nlet get_event_name = (customDimensions: dynamic, message: string) {  iff(customDimensions[\"event.name\"] == \"\", message, customDimensions[\"event.name\"]) };\r\nlet get_evaluator_name = (customDimensions: dynamic, event_name: string) { iff(customDimensions[\"gen_ai.evaluator.name\"] == \"\", split(event_name, \".\")[2], tostring(customDimensions[\"gen_ai.evaluator.name\"])) };\r\nlet get_response_id = (customDimensions: dynamic) { \r\n    iff(\r\n        customDimensions[\"gen_ai.response.id\"] == \"\", \r\n        iff(customDimensions[\"gen_ai.thread.run.id\"] == \"\", \"\", strcat(tostring(customDimensions[\"gen_ai.thread.id\"]), \"/\", tostring(customDimensions[\"gen_ai.thread.run.id\"]))),\r\n        tostring(customDimensions[\"gen_ai.response.id\"]))\r\n}; \r\nlet inference_calls = dependencies\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| project customDimensions, cloud_RoleName, timestamp, response_id=get_response_id(customDimensions), model=tostring(get_model(customDimensions));\r\n// Dedup only for get_thread_run\r\nlet deduped_inference_calls =\r\n  union\r\n  (\r\n    inference_calls\r\n    | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n  ),\r\n  (\r\n    inference_calls\r\n    | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n    | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n  )\r\n  | project response_id, model;\r\nlet evals = traces\r\n| where timestamp {TimeRange}\r\n| where filter_model_and_app(customDimensions, cloud_RoleName)\r\n| extend event_name = get_event_name(customDimensions, message)\r\n| where event_name startswith \"gen_ai.evaluation\"\r\n| extend evaluator_name = get_evaluator_name(customDimensions, event_name), score = todouble(customDimensions[\"gen_ai.evaluation.score\"]), response_id=get_response_id(customDimensions), evaluator_id=tostring(customDimensions[\"gen_ai.evaluator.id\"]);\r\nevals \r\n| join kind=leftouter deduped_inference_calls on response_id\r\n| project response_id, model, score, evaluator_name, timestamp, evaluator_id\r\n| where evaluator_id !in~ (\"azureai://built-in/evaluators/code_vulnerability\", \"azureai://built-in/evaluators/hate_unfairness\", \"azureai://built-in/evaluators/indirect_attack\", \"azureai://built-in/evaluators/self_harm\", \"azureai://built-in/evaluators/sexual\", \"azureai://built-in/evaluators/violence\")\r\n| summarize avg(score) by tostring(evaluator_name), bin(timestamp, {TimeRange:grain})",
          "size": 1,
          "title": "AI Quality average score",
          "noDataMessage": "The query returned no results. Note that you must instrument client application with distributed tracing to enable filtering by Application and Model. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "linechart",
          "chartSettings": {
            "showMetrics": false,
            "showLegend": true,
            "simpleLegendSettings": {
              "position": "bottom"
            },
            "xSettings": {
              "label": "Time"
            },
            "ySettings": {
              "label": "Average score"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "name": "query - 4",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 0,
          "y": 22,
          "w": 24,
          "h": 8
        },
        "id": "baf17bd7-d0a9-4189-8a62-c3671816fc66"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application = dynamic([{Application}]);let model = dynamic([{Model}]);\r\nlet get_model = (customDimensions: dynamic) {  iff(customDimensions[\"gen_ai.request.model\"] == \"\", customDimensions[\"gen_ai.response.model\"], customDimensions[\"gen_ai.request.model\"]) };\r\nlet is_inference_call = (customDimensions: dynamic) {\r\n   // this filters out non-genai calls/non-inference calls like create_agent\r\n  customDimensions[\"gen_ai.system\"] != \"\" and customDimensions[\"gen_ai.operation.name\"] in (\"chat\", \"process_thread_run\", \"text_completion\",\"get_thread_run\")\r\n};\r\nlet filter_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n  (\"*\" in (model) or array_length(model) == 0 or get_model(customDimensions) in (model)) and \r\n  ('*' in (application) or array_length(application) == 0 or app_name in (application))\r\n};\r\nlet filter_inference_model_and_app = (customDimensions: dynamic, app_name: string) {\r\n  is_inference_call(customDimensions) == true and filter_model_and_app(customDimensions, app_name) == true\r\n};\r\nlet change_percent = (final: double, initial: double) {iff(initial == 0, iff(final == 0, real(0), real(+inf)), (final-initial) / initial * 100)};\r\nlet get_event_name = (customDimensions: dynamic, message: string) {  iff(customDimensions[\"event.name\"] == \"\", message, customDimensions[\"event.name\"]) };\r\nlet get_evaluator_name = (customDimensions: dynamic, event_name: string) { iff(customDimensions[\"gen_ai.evaluator.name\"] == \"\", split(event_name, \".\")[2], tostring(customDimensions[\"gen_ai.evaluator.name\"])) };\r\nlet get_response_id = (customDimensions: dynamic) { \r\n    iff(\r\n        customDimensions[\"gen_ai.response.id\"] == \"\", \r\n        iff(customDimensions[\"gen_ai.thread.run.id\"] == \"\", \"\", strcat(tostring(customDimensions[\"gen_ai.thread.id\"]), \"/\", tostring(customDimensions[\"gen_ai.thread.run.id\"]))),\r\n        tostring(customDimensions[\"gen_ai.response.id\"]))\r\n}; \r\nlet inference_calls = dependencies\r\n| where timestamp {TimeRange}\r\n| where filter_inference_model_and_app(customDimensions, cloud_RoleName) == true\r\n| project customDimensions, cloud_RoleName, timestamp, response_id=get_response_id(customDimensions), model=tostring(get_model(customDimensions));\r\n// Dedup only for get_thread_run\r\nlet deduped_inference_calls =\r\n  union\r\n  (\r\n    inference_calls\r\n    | where customDimensions[\"gen_ai.operation.name\"] != \"get_thread_run\"\r\n  ),\r\n  (\r\n    inference_calls\r\n    | where customDimensions[\"gen_ai.operation.name\"] == \"get_thread_run\"\r\n    | summarize arg_max(timestamp, *) by tostring(customDimensions[\"gen_ai.thread.run.id\"])\r\n  )\r\n  | project response_id, model;\r\nlet evals = traces\r\n| where timestamp {TimeRange}\r\n| where filter_model_and_app(customDimensions, cloud_RoleName)\r\n| extend event_name = get_event_name(customDimensions, message)\r\n| where event_name startswith \"gen_ai.evaluation\"\r\n| extend evaluator_name = get_evaluator_name(customDimensions, event_name), score = todouble(customDimensions[\"gen_ai.evaluation.score\"]), response_id=get_response_id(customDimensions), evaluator_id=tostring(customDimensions[\"gen_ai.evaluator.id\"]);\r\nevals \r\n| join kind=leftouter deduped_inference_calls on response_id\r\n| project response_id, model, score, evaluator_name, timestamp, evaluator_id\r\n| where evaluator_id in~ (\"azureai://built-in/evaluators/code_vulnerability\", \"azureai://built-in/evaluators/hate_unfairness\", \"azureai://built-in/evaluators/indirect_attack\", \"azureai://built-in/evaluators/self_harm\", \"azureai://built-in/evaluators/sexual\", \"azureai://built-in/evaluators/violence\")\r\n| summarize avg(score) by tostring(evaluator_name), bin(timestamp, {TimeRange:grain})",
          "size": 1,
          "title": "Risk + safety average score",
          "noDataMessage": "The query returned no results. Note that you must instrument client application with distributed tracing to enable filtering by Application and Model. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "linechart",
          "chartSettings": {
            "showMetrics": false,
            "showLegend": true,
            "simpleLegendSettings": {
              "position": "bottom"
            },
            "xSettings": {
              "label": "Time"
            },
            "ySettings": {
              "label": "Average score"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "customWidth": "66.67",
        "name": "Daily safety average score",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 0,
          "y": 30,
          "w": 16,
          "h": 6
        },
        "id": "a02e6c4f-5318-4e47-8c74-94e601ec8bf9"
      },
      {
        "type": 3,
        "content": {
          "version": "KqlItem/1.0",
          "query": "let application=dynamic([{Application}]);\r\nlet model=dynamic([{Model}]);\r\nlet response_ids=(\r\ndependencies\r\n| where customDimensions[\"gen_ai.operation.name\"] == \"chat\" and (\"*\" in (model) or array_length(model) == 0 or customDimensions[\"gen_ai.response.model\"] in (model))\r\n| where ('*' in (application) or array_length(application) == 0 or cloud_RoleName in (application)) and timestamp {TimeRange}\r\n| project customDimensions.[\"gen_ai.response.id\"]\r\n); \r\ntraces\r\n| where customDimensions[\"event.name\"] == \"gen_ai.evaluation.user_feedback\"\r\n| where ('*' in (application) or array_length(application) == 0 or cloud_RoleName in (application)) and timestamp {TimeRange} \r\n| where customDimensions.[\"gen_ai.response.id\"] in (response_ids)\r\n| extend FeedbackType = case(toint(customDimensions[\"gen_ai.evaluation.score\"]) == -1, \"Positive\", toint(customDimensions[\"gen_ai.evaluation.score\"]) == 1, \"Negative\", \"Unknown\")\r\n| summarize Count = count() by FeedbackType",
          "size": 1,
          "title": "User feedback",
          "noDataMessage": "The query returned no results. Try updating the time range or changing filters. To learn more about monitoring, go to aka.ms/AzureAIFoundry/Observability/Monitoring",
          "timeContextFromParameter": "TimeRange",
          "headingLevel": 4,
          "queryType": 0,
          "resourceType": "microsoft.insights/components",
          "crossComponentResources": [
            "{ApplicationInsights}"
          ],
          "visualization": "piechart",
          "chartSettings": {
            "showMetrics": false,
            "showLegend": true,
            "seriesLabelSettings": [
              {
                "seriesName": "Positive",
                "label": "Thumbs up",
                "color": "greenDark"
              },
              {
                "seriesName": "Negative",
                "label": "Thumbs down",
                "color": "red"
              }
            ],
            "simpleLegendSettings": {
              "position": "bottom"
            }
          },
          "showAnalytics": true,
          "showViewButton": false
        },
        "customWidth": "33.3",
        "name": "query - 6",
        "styleSettings": {
          "showBorder": true,
          "borderStyle": "light rounded",
          "padding": "16px",
          "x": 16,
          "y": 30,
          "w": 8,
          "h": 6
        },
        "id": "43bd5f18-c128-4585-8fb7-cfa0f6e7b5d0"
      }
    ],
    "layout": {
      "type": "grid",
      "options": {
        "rowHeight": 44
      }
    },
    "$schema": "https://github.com/Microsoft/Application-Insights-Workbooks/blob/master/schema/workbook.json"
}
