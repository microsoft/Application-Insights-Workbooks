{
  "version": "Notebook/1.0",
  "items": [
    {
      "type": 9,
      "content": {
        "version": "KqlParameterItem/1.0",
        "parameters": [
          {
            "id": "9f5cce7e-986c-4be7-a62d-d0af1cf35b10",
            "version": "KqlParameterItem/1.0",
            "name": "ioMetric",
            "label": "Metric",
            "type": 10,
            "description": "Select an IO metric to show on the heatmap",
            "isRequired": true,
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "jsonData": "[\r\n    {\"value\":\"latency\",\"label\":\"Latency\"},\r\n    {\"value\":\"iops\",\"label\":\"IOPS\"},\r\n    {\"value\":\"bps\",\"label\":\"Throughput\"}\r\n]",
            "value": "latency"
          },
          {
            "id": "3bf03c31-f68a-4ebf-b8be-d191353b24b8",
            "version": "KqlParameterItem/1.0",
            "name": "ioDirection",
            "label": "IO direction",
            "type": 10,
            "description": "Select the direction of IO to show: all database file IO, reads, or writes",
            "isRequired": true,
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "jsonData": "[\r\n    {\"value\":\"all\",\"label\":\"All\"},\r\n    {\"value\":\"read\",\"label\":\"Read\"},\r\n    {\"value\":\"write\",\"label\":\"Write\"}\r\n]",
            "value": "all"
          },
          {
            "id": "8c906d60-0b93-46ac-852c-c23b638aaeb9",
            "version": "KqlParameterItem/1.0",
            "name": "ioFileType",
            "label": "Database files",
            "type": 10,
            "description": "Select \"All\" to include IO against all types of database files; select \"Data\" or \"Transaction log\" to include IO against these database files types only",
            "isRequired": true,
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "jsonData": "[\r\n    {\"value\":\"All\",\"label\":\"All\"},\r\n    {\"value\":\"Data\",\"label\":\"Data\"},\r\n    {\"value\":\"Log\",\"label\":\"Transaction log\"}\r\n]",
            "value": "All"
          },
          {
            "id": "ef2a3806-e806-484f-8f49-694dc5a3c0f3",
            "version": "KqlParameterItem/1.0",
            "name": "ioDatabaseType",
            "label": "Databases",
            "type": 10,
            "description": "\"User databases\" includes IO against all user databases; \"System\" includes IO against the master, model, and msdb databases; \"tempdb\" includes IO against the tempdb database only",
            "isRequired": true,
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "jsonData": "[\r\n    {\"value\":\"all\",\"label\":\"All\"},\r\n    {\"value\":\"user\",\"label\":\"User\"},\r\n    {\"value\":\"system\",\"label\":\"System\"},\r\n    {\"value\":\"tempdb\",\"label\":\"tempdb\"}\r\n]",
            "value": "all"
          }
        ],
        "style": "above",
        "queryType": 0,
        "resourceType": "microsoft.operationalinsights/workspaces"
      },
      "name": "io_parameters"
    },
    {
      "type": 3,
      "content": {
        "version": "KqlItem/1.0",
        "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"let io = materialize (\\r\\nsqlmi_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n{managedInstanceNameFilter}\\r\\n| where \\\"{ioFileType}\\\" == \\\"All\\\" or (\\\"{ioFileType}\\\" != \\\"All\\\" and file_type == \\\"{ioFileType}\\\")\\r\\n| where \\\"{ioDatabaseType}\\\" == \\\"all\\\" or (\\\"{ioDatabaseType}\\\" == \\\"user\\\" and database_id > 4) or (\\\"{ioDatabaseType}\\\" == \\\"system\\\" and database_id in (1,3,4)) or (\\\"{ioDatabaseType}\\\" == \\\"tempdb\\\" and database_id == 2)\\r\\n| project sample_time_utc, managed_instance_name, replica_type, file_id, database_id, io_snapshot_sample_ms, num_of_reads, num_of_writes\\r\\n| partition hint.strategy = shuffle by managed_instance_name\\r\\n(\\r\\nsort by replica_type asc, database_id asc, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null)),\\r\\n         delta_num_of_reads = iif(num_of_reads >= prev(num_of_reads) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), num_of_reads - prev(num_of_reads), long(null)),\\r\\n         delta_num_of_writes = iif(num_of_writes >= prev(num_of_writes) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), num_of_writes - prev(num_of_writes), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize total_reads = sum(delta_num_of_reads),\\r\\n            total_writes = sum(delta_num_of_writes),\\r\\n            count_samples = dcount(sample_time_utc),\\r\\n            min_sample_time_utc = min(sample_time_utc),\\r\\n            max_sample_time_utc = max(sample_time_utc)\\r\\n            by managed_instance_name, replica_type, binned_sample_time_utc = bin(sample_time_utc, {timeRange:grain})\\r\\n| extend total_ios = case(\\r\\n                         \\\"{ioDirection}\\\" == \\\"all\\\", total_reads + total_writes,\\r\\n                         \\\"{ioDirection}\\\" == \\\"read\\\", total_reads,\\r\\n                         \\\"{ioDirection}\\\" == \\\"write\\\", total_writes,\\r\\n                         long(null)\\r\\n                         )\\r\\n)\\r\\n);\\r\\nlet total_sample_count = (\\r\\nio\\r\\n| summarize total_count_samples = sum(count_samples) by managed_instance_name, replica_type\\r\\n);\\r\\nlet expected_sample_count = toscalar(\\r\\ntotal_sample_count\\r\\n| summarize percentile(total_count_samples, 90)\\r\\n);\\r\\nlet io_timeline = \\r\\n(\\r\\nio\\r\\n| make-series ios_timeline = max(total_ios) default = long(null) on binned_sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by managed_instance_name, replica_type\\r\\n| project series_fill_linear(ios_timeline, int(null), false), managed_instance_name, replica_type\\r\\n);\\r\\nlet instance_properties = (\\r\\nsqlmi_instance_properties\\r\\n| where sample_time_utc between ({timeRange:start} .. {timeRange:end})\\r\\n{managedInstanceNameFilter}\\r\\n| summarize arg_max(sample_time_utc, service_tier = case(service_tier =~ \\\"GeneralPurpose\\\", \\\"General Purpose\\\", service_tier =~ \\\"BusinessCritical\\\", \\\"Business Critical\\\", service_tier)) by managed_instance_name, replica_type\\r\\n);\\r\\nio\\r\\n| lookup total_sample_count on managed_instance_name, replica_type\\r\\n| summarize iops = toreal(sum(total_ios)) / datetime_diff(\\\"millisecond\\\", max(max_sample_time_utc), min(min_sample_time_utc)) * 1000,\\r\\n            count_samples = sum(count_samples)\\r\\n            by managed_instance_name, replica_type\\r\\n| join kind=leftouter io_timeline on managed_instance_name, replica_type\\r\\n| join kind=leftouter instance_properties on managed_instance_name, replica_type\\r\\n| project managed_instance_name, replica_type, service_tier, iops = iif(toreal(count_samples)/expected_sample_count < 0.5, real(null), iops), ios_timeline,\\r\\ngrouper = case(\\r\\n\\\"{HeatmapGroupBy}\\\" == \\\"service_tier\\\", service_tier,\\r\\nmanaged_instance_name\\r\\n),\\r\\nreplica_type_indicator = case(\\r\\nreplica_type == \\\"Primary\\\", \\\"ðŸ”µ\\\",\\r\\nreplica_type == \\\"HA secondary\\\", \\\"ðŸ”˜\\\",\\r\\n\\\"\\\"\\r\\n)\\r\\n| project managed_instance_name, decorated_managed_instance_name = strcat(replica_type_indicator, managed_instance_name), replica_type, iops, ios_timeline, grouper = iif(\\\"{HeatmapGroupBy}\\\" == \\\"none\\\", \\\"\\\", grouper), top_tooltip = strcat(managed_instance_name, \\\" | \\\", replica_type_indicator, replica_type), ha_secondary = tolower(tostring(replica_type == \\\"HA secondary\\\"))\\r\\n| top {topHitters} by iops desc\\r\\n| sort by iops desc, tolower(grouper) asc, tolower(managed_instance_name) asc, iif(replica_type == \\\"HA secondary\\\", 1, 0) asc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
        "size": 3,
        "showAnalytics": true,
        "noDataMessage": "There is no data for specified parameters.",
        "showExportToExcel": true,
        "queryType": 9,
        "visualization": "graph",
        "graphSettings": {
          "type": 2,
          "topContent": {
            "columnMatch": "decorated_managed_instance_name",
            "formatter": 1,
            "formatOptions": {
              "linkTarget": "WorkbookTemplate",
              "workbookContext": {
                "componentIdSource": "workbook",
                "resourceIdsSource": "workbook",
                "templateIdSource": "static",
                "templateId": "Community-Workbooks/Database watcher/Azure SQL Managed Instance/instance",
                "typeSource": "workbook",
                "gallerySource": "default",
                "locationSource": "workbook",
                "workbookName": "Managed instance",
                "passSpecificParams": true,
                "templateParameters": [
                  {
                    "name": "managedInstanceName",
                    "source": "column",
                    "value": "managed_instance_name"
                  },
                  {
                    "name": "timeRange",
                    "source": "parameter",
                    "value": "timeRange"
                  },
                  {
                    "name": "linkAdxClusterUri",
                    "source": "parameter",
                    "value": "adxClusterUri"
                  },
                  {
                    "name": "linkAdxDatabase",
                    "source": "parameter",
                    "value": "adxDatabase"
                  },
                  {
                    "name": "tabName",
                    "source": "static",
                    "value": "Overview"
                  },
                  {
                    "name": "showDescriptions",
                    "source": "parameter",
                    "value": "showDescriptions"
                  },
                  {
                    "name": "haReplica",
                    "source": "column",
                    "value": "ha_secondary"
                  }
                ],
                "viewerMode": true
              }
            },
            "tooltipFormat": {
              "tooltip": "[\"top_tooltip\"]"
            }
          },
          "centerContent": {
            "columnMatch": "iops",
            "formatter": 12,
            "formatOptions": {
              "palette": "none"
            },
            "numberFormat": {
              "unit": 31,
              "options": {
                "style": "decimal",
                "useGrouping": true,
                "maximumFractionDigits": 1
              },
              "emptyValCustomText": "N/A"
            },
            "tooltipFormat": {
              "tooltip": "Average read or write IOPS for the selected time range. Shows \"N/A\" if the number of samples is insufficient."
            }
          },
          "bottomContent": {
            "columnMatch": "ios_timeline",
            "formatter": 21,
            "formatOptions": {
              "palette": "purple"
            },
            "tooltipFormat": {
              "tooltip": "Total read or write IOs over selected time range"
            }
          },
          "hivesContent": {
            "columnMatch": "grouper",
            "formatter": 18,
            "formatOptions": {
              "thresholdsOptions": "icons",
              "thresholdsGrid": [
                {
                  "operator": "is Empty",
                  "representation": "Blank",
                  "text": "{0}{1}"
                },
                {
                  "operator": "Default",
                  "thresholdValue": null,
                  "representation": "ResourceFlat",
                  "text": "{0}{1}"
                }
              ]
            }
          },
          "nodeIdField": "managed_instance_name",
          "graphOrientation": 3,
          "showOrientationToggles": false,
          "nodeSize": null,
          "staticNodeSize": 150,
          "colorSettings": {
            "nodeColorField": "iops",
            "type": 4,
            "heatmapPalette": "greenBlue",
            "heatmapMin": null,
            "heatmapMax": null,
            "emptyValueColor": "gray"
          },
          "groupByField": "grouper",
          "hivesMargin": 5,
          "edgeColorSettings": null
        }
      },
      "conditionalVisibility": {
        "parameterName": "ioMetric",
        "comparison": "isEqualTo",
        "value": "iops"
      },
      "name": "storage_io_ios_heatmap"
    },
    {
      "type": 3,
      "content": {
        "version": "KqlItem/1.0",
        "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"let io = materialize (\\r\\nsqlmi_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n{managedInstanceNameFilter}\\r\\n| where \\\"{ioFileType}\\\" == \\\"All\\\" or (\\\"{ioFileType}\\\" != \\\"All\\\" and file_type == \\\"{ioFileType}\\\")\\r\\n| where \\\"{ioDatabaseType}\\\" == \\\"all\\\" or (\\\"{ioDatabaseType}\\\" == \\\"user\\\" and database_id > 4) or (\\\"{ioDatabaseType}\\\" == \\\"system\\\" and database_id in (1,3,4)) or (\\\"{ioDatabaseType}\\\" == \\\"tempdb\\\" and database_id == 2)\\r\\n| project sample_time_utc, managed_instance_name, replica_type, file_id, database_id, io_snapshot_sample_ms, num_of_bytes_read, num_of_bytes_written\\r\\n| partition hint.strategy = shuffle by managed_instance_name\\r\\n(\\r\\nsort by replica_type asc, database_id asc, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null)),\\r\\n         delta_num_of_bytes_read = iif(num_of_bytes_read >= prev(num_of_bytes_read) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), num_of_bytes_read - prev(num_of_bytes_read), long(null)),\\r\\n         delta_num_of_bytes_written = iif(num_of_bytes_written >= prev(num_of_bytes_written) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), num_of_bytes_written - prev(num_of_bytes_written), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize total_read_bytes = sum(delta_num_of_bytes_read),\\r\\n            total_written_bytes = sum(delta_num_of_bytes_written),\\r\\n            count_samples = dcount(sample_time_utc),\\r\\n            min_sample_time_utc = min(sample_time_utc),\\r\\n            max_sample_time_utc = max(sample_time_utc)\\r\\nby managed_instance_name, replica_type, binned_sample_time_utc = bin(sample_time_utc, {timeRange:grain})\\r\\n| extend total_bytes = case(\\r\\n                           \\\"{ioDirection}\\\" == \\\"all\\\", total_read_bytes + total_written_bytes,\\r\\n                           \\\"{ioDirection}\\\" == \\\"read\\\", total_read_bytes,\\r\\n                           \\\"{ioDirection}\\\" == \\\"write\\\", total_written_bytes,\\r\\n                           long(null)\\r\\n                           )\\r\\n)\\r\\n);\\r\\nlet total_sample_count = (\\r\\nio\\r\\n| summarize total_count_samples = sum(count_samples) by managed_instance_name, replica_type\\r\\n);\\r\\nlet expected_sample_count = toscalar(\\r\\ntotal_sample_count\\r\\n| summarize percentile(total_count_samples, 90)\\r\\n);\\r\\nlet io_timeline = \\r\\n(\\r\\nio\\r\\n| make-series bytes_timeline = max(total_bytes) default = long(null) on binned_sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by managed_instance_name, replica_type\\r\\n| project series_fill_linear(bytes_timeline, int(null), false), managed_instance_name, replica_type\\r\\n);\\r\\nlet instance_properties = (\\r\\nsqlmi_instance_properties\\r\\n| where sample_time_utc between ({timeRange:start} .. {timeRange:end})\\r\\n{managedInstanceNameFilter}\\r\\n| summarize arg_max(sample_time_utc, service_tier = case(service_tier =~ \\\"GeneralPurpose\\\", \\\"General Purpose\\\", service_tier =~ \\\"BusinessCritical\\\", \\\"Business Critical\\\", service_tier)) by managed_instance_name, replica_type\\r\\n);\\r\\nio\\r\\n| lookup total_sample_count on managed_instance_name, replica_type\\r\\n| summarize bps = toreal(sum(total_bytes)) / datetime_diff(\\\"millisecond\\\", max(max_sample_time_utc), min(min_sample_time_utc)) * 1000,\\r\\n            count_samples = sum(count_samples)\\r\\n            by managed_instance_name, replica_type\\r\\n| join kind=leftouter io_timeline on managed_instance_name, replica_type\\r\\n| join kind=leftouter instance_properties on managed_instance_name, replica_type\\r\\n| project managed_instance_name, replica_type, service_tier, bps = iif(toreal(count_samples)/expected_sample_count < 0.5, real(null), bps), bytes_timeline,\\r\\ngrouper = case(\\r\\n\\\"{HeatmapGroupBy}\\\" == \\\"service_tier\\\", service_tier,\\r\\nmanaged_instance_name\\r\\n),\\r\\nreplica_type_indicator = case(\\r\\nreplica_type == \\\"Primary\\\", \\\"ðŸ”µ\\\",\\r\\nreplica_type == \\\"HA secondary\\\", \\\"ðŸ”˜\\\",\\r\\n\\\"\\\"\\r\\n)\\r\\n| project managed_instance_name, decorated_managed_instance_name = strcat(replica_type_indicator, managed_instance_name), replica_type, bps, bytes_timeline, grouper = iif(\\\"{HeatmapGroupBy}\\\" == \\\"none\\\", \\\"\\\", grouper), top_tooltip = strcat(managed_instance_name, \\\" | \\\", replica_type_indicator, replica_type), ha_secondary = tolower(tostring(replica_type == \\\"HA secondary\\\"))\\r\\n| top {topHitters} by bps desc\\r\\n| sort by bps desc, tolower(grouper) asc, tolower(managed_instance_name) asc, iif(replica_type == \\\"HA secondary\\\", 1, 0) asc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
        "size": 3,
        "showAnalytics": true,
        "noDataMessage": "There is no data for specified parameters.",
        "showExportToExcel": true,
        "queryType": 9,
        "visualization": "graph",
        "graphSettings": {
          "type": 2,
          "topContent": {
            "columnMatch": "decorated_managed_instance_name",
            "formatter": 1,
            "formatOptions": {
              "linkTarget": "WorkbookTemplate",
              "workbookContext": {
                "componentIdSource": "workbook",
                "resourceIdsSource": "workbook",
                "templateIdSource": "static",
                "templateId": "Community-Workbooks/Database watcher/Azure SQL Managed Instance/instance",
                "typeSource": "workbook",
                "gallerySource": "default",
                "locationSource": "workbook",
                "workbookName": "Managed instance",
                "passSpecificParams": true,
                "templateParameters": [
                  {
                    "name": "managedInstanceName",
                    "source": "column",
                    "value": "managed_instance_name"
                  },
                  {
                    "name": "timeRange",
                    "source": "parameter",
                    "value": "timeRange"
                  },
                  {
                    "name": "linkAdxClusterUri",
                    "source": "parameter",
                    "value": "adxClusterUri"
                  },
                  {
                    "name": "linkAdxDatabase",
                    "source": "parameter",
                    "value": "adxDatabase"
                  },
                  {
                    "name": "tabName",
                    "source": "static",
                    "value": "Overview"
                  },
                  {
                    "name": "showDescriptions",
                    "source": "parameter",
                    "value": "showDescriptions"
                  },
                  {
                    "name": "haReplica",
                    "source": "column",
                    "value": "ha_secondary"
                  }
                ],
                "viewerMode": true
              }
            },
            "tooltipFormat": {
              "tooltip": "[\"top_tooltip\"]"
            }
          },
          "centerContent": {
            "columnMatch": "bps",
            "formatter": 12,
            "formatOptions": {
              "palette": "none"
            },
            "numberFormat": {
              "unit": 11,
              "options": {
                "style": "decimal",
                "useGrouping": true,
                "maximumFractionDigits": 1
              },
              "emptyValCustomText": "N/A"
            },
            "tooltipFormat": {
              "tooltip": "Average read or write throughput for the selected time range. Shows \"N/A\" if the number of samples is insufficient."
            }
          },
          "bottomContent": {
            "columnMatch": "bytes_timeline",
            "formatter": 21,
            "formatOptions": {
              "palette": "purple"
            },
            "tooltipFormat": {
              "tooltip": "Total read or write bytes over selected time range"
            }
          },
          "hivesContent": {
            "columnMatch": "grouper",
            "formatter": 18,
            "formatOptions": {
              "thresholdsOptions": "icons",
              "thresholdsGrid": [
                {
                  "operator": "is Empty",
                  "representation": "Blank",
                  "text": "{0}{1}"
                },
                {
                  "operator": "Default",
                  "thresholdValue": null,
                  "representation": "ResourceFlat",
                  "text": "{0}{1}"
                }
              ]
            }
          },
          "nodeIdField": "managed_instance_name",
          "graphOrientation": 3,
          "showOrientationToggles": false,
          "nodeSize": null,
          "staticNodeSize": 150,
          "colorSettings": {
            "nodeColorField": "bps",
            "type": 4,
            "heatmapPalette": "greenBlue",
            "heatmapMin": null,
            "heatmapMax": null,
            "emptyValueColor": "gray"
          },
          "groupByField": "grouper",
          "hivesMargin": 5,
          "edgeColorSettings": null
        }
      },
      "conditionalVisibility": {
        "parameterName": "ioMetric",
        "comparison": "isEqualTo",
        "value": "bps"
      },
      "name": "storage_io_bytes_heatmap"
    },
    {
      "type": 3,
      "content": {
        "version": "KqlItem/1.0",
        "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"let io = materialize (\\r\\nsqlmi_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n{managedInstanceNameFilter}\\r\\n| where \\\"{ioFileType}\\\" == \\\"All\\\" or (\\\"{ioFileType}\\\" != \\\"All\\\" and file_type == \\\"{ioFileType}\\\")\\r\\n| where \\\"{ioDatabaseType}\\\" == \\\"all\\\" or (\\\"{ioDatabaseType}\\\" == \\\"user\\\" and database_id > 4) or (\\\"{ioDatabaseType}\\\" == \\\"system\\\" and database_id in (1,3,4)) or (\\\"{ioDatabaseType}\\\" == \\\"tempdb\\\" and database_id == 2)\\r\\n| project sample_time_utc, managed_instance_name, replica_type, file_id, database_id, io_snapshot_sample_ms, io_stall_read_ms, io_stall_write_ms, num_of_reads, num_of_writes\\r\\n| partition hint.strategy = shuffle by managed_instance_name\\r\\n(\\r\\nsort by replica_type asc, database_id asc, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null)),\\r\\n         delta_num_of_reads = iif(num_of_reads >= prev(num_of_reads) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), num_of_reads - prev(num_of_reads), long(null)),\\r\\n         delta_num_of_writes = iif(num_of_writes >= prev(num_of_writes) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), num_of_writes - prev(num_of_writes), long(null)),\\r\\n         delta_io_stall_read_ms = iif(io_stall_read_ms >= prev(io_stall_read_ms) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), io_stall_read_ms - prev(io_stall_read_ms), long(null)),\\r\\n         delta_io_stall_write_ms = iif(io_stall_write_ms >= prev(io_stall_write_ms) and database_id == prev(database_id) and file_id == prev(file_id) and replica_type == prev(replica_type), io_stall_write_ms - prev(io_stall_write_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize total_reads = sum(delta_num_of_reads),\\r\\n            total_writes = sum(delta_num_of_writes),\\r\\n            total_read_stall_time = sum(delta_io_stall_read_ms),\\r\\n            total_write_stall_time = sum(delta_io_stall_write_ms),\\r\\n            count_samples = dcount(sample_time_utc)\\r\\n            by managed_instance_name, replica_type, binned_sample_time_utc = bin(sample_time_utc, {timeRange:grain})\\r\\n| extend total_stall_time = case(\\r\\n                                \\\"{ioDirection}\\\" == \\\"all\\\", toreal(total_read_stall_time) + toreal(total_write_stall_time),\\r\\n                                \\\"{ioDirection}\\\" == \\\"read\\\", toreal(total_read_stall_time),\\r\\n                                \\\"{ioDirection}\\\" == \\\"write\\\", toreal(total_write_stall_time),\\r\\n                                real(null)\\r\\n                                ),\\r\\n         total_ios = case(\\r\\n                         \\\"{ioDirection}\\\" == \\\"all\\\", toreal(total_reads) + toreal(total_writes),\\r\\n                         \\\"{ioDirection}\\\" == \\\"read\\\", toreal(total_reads),\\r\\n                         \\\"{ioDirection}\\\" == \\\"write\\\", toreal(total_writes),\\r\\n                         real(null)\\r\\n                         )\\r\\n| project-away total_read_stall_time, total_write_stall_time, total_reads, total_writes\\r\\n)\\r\\n);\\r\\nlet total_sample_count = (\\r\\nio\\r\\n| summarize total_count_samples = sum(count_samples) by managed_instance_name, replica_type\\r\\n);\\r\\nlet expected_sample_count = toscalar(\\r\\ntotal_sample_count\\r\\n| summarize percentile(total_count_samples, 90)\\r\\n);\\r\\nlet io_timeline = \\r\\n(\\r\\nio\\r\\n| make-series latency_timeline = sum(total_stall_time)/sum(total_ios) default = long(null) on binned_sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by managed_instance_name, replica_type\\r\\n| project series_fill_linear(latency_timeline, int(null), false), managed_instance_name, replica_type\\r\\n);\\r\\nlet instance_properties = (\\r\\nsqlmi_instance_properties\\r\\n| where sample_time_utc between ({timeRange:start} .. {timeRange:end})\\r\\n{managedInstanceNameFilter}\\r\\n| summarize arg_max(sample_time_utc, service_tier = case(service_tier =~ \\\"GeneralPurpose\\\", \\\"General Purpose\\\", service_tier =~ \\\"BusinessCritical\\\", \\\"Business Critical\\\", service_tier)) by managed_instance_name, replica_type\\r\\n);\\r\\nio\\r\\n| lookup total_sample_count on managed_instance_name, replica_type\\r\\n| summarize latency = iif(sum(total_ios) > 0, sum(total_stall_time)/sum(total_ios), real(null)),\\r\\n            count_samples = sum(count_samples)\\r\\n            by managed_instance_name, replica_type\\r\\n| join kind=leftouter io_timeline on managed_instance_name, replica_type\\r\\n| join kind=leftouter instance_properties on managed_instance_name, replica_type\\r\\n| project managed_instance_name, replica_type, service_tier, latency = iif(toreal(count_samples)/expected_sample_count < 0.5, real(null), latency), latency_timeline,\\r\\ngrouper = case(\\r\\n\\\"{HeatmapGroupBy}\\\" == \\\"service_tier\\\", service_tier,\\r\\nmanaged_instance_name\\r\\n),\\r\\nreplica_type_indicator = case(\\r\\nreplica_type == \\\"Primary\\\", \\\"ðŸ”µ\\\",\\r\\nreplica_type == \\\"HA secondary\\\", \\\"ðŸ”˜\\\",\\r\\n\\\"\\\"\\r\\n)\\r\\n| project managed_instance_name, decorated_managed_instance_name = strcat(replica_type_indicator, managed_instance_name), replica_type, latency, latency_timeline, grouper = iif(\\\"{HeatmapGroupBy}\\\" == \\\"none\\\", \\\"\\\", grouper), top_tooltip = strcat(managed_instance_name, \\\" | \\\", replica_type_indicator, replica_type), ha_secondary = tolower(tostring(replica_type == \\\"HA secondary\\\"))\\r\\n| top {topHitters} by latency desc\\r\\n| sort by latency desc, tolower(grouper) asc, tolower(managed_instance_name) asc, iif(replica_type == \\\"HA secondary\\\", 1, 0) asc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
        "size": 3,
        "showAnalytics": true,
        "noDataMessage": "There is no data for specified parameters.",
        "showExportToExcel": true,
        "queryType": 9,
        "visualization": "graph",
        "graphSettings": {
          "type": 2,
          "topContent": {
            "columnMatch": "decorated_managed_instance_name",
            "formatter": 1,
            "formatOptions": {
              "linkTarget": "WorkbookTemplate",
              "workbookContext": {
                "componentIdSource": "workbook",
                "resourceIdsSource": "workbook",
                "templateIdSource": "static",
                "templateId": "Community-Workbooks/Database watcher/Azure SQL Managed Instance/instance",
                "typeSource": "workbook",
                "gallerySource": "default",
                "locationSource": "workbook",
                "workbookName": "Managed instance",
                "passSpecificParams": true,
                "templateParameters": [
                  {
                    "name": "managedInstanceName",
                    "source": "column",
                    "value": "managed_instance_name"
                  },
                  {
                    "name": "timeRange",
                    "source": "parameter",
                    "value": "timeRange"
                  },
                  {
                    "name": "linkAdxClusterUri",
                    "source": "parameter",
                    "value": "adxClusterUri"
                  },
                  {
                    "name": "linkAdxDatabase",
                    "source": "parameter",
                    "value": "adxDatabase"
                  },
                  {
                    "name": "tabName",
                    "source": "static",
                    "value": "Overview"
                  },
                  {
                    "name": "showDescriptions",
                    "source": "parameter",
                    "value": "showDescriptions"
                  },
                  {
                    "name": "haReplica",
                    "source": "column",
                    "value": "ha_secondary"
                  }
                ],
                "viewerMode": true
              }
            },
            "tooltipFormat": {
              "tooltip": "[\"top_tooltip\"]"
            }
          },
          "centerContent": {
            "columnMatch": "latency",
            "formatter": 12,
            "formatOptions": {
              "palette": "none"
            },
            "numberFormat": {
              "unit": 23,
              "options": {
                "style": "decimal",
                "useGrouping": true,
                "maximumFractionDigits": 1
              },
              "emptyValCustomText": "N/A"
            },
            "tooltipFormat": {
              "tooltip": "Average read or write IO latency for selected time range. Shows \"N/A\" if the number of samples is insufficient."
            }
          },
          "bottomContent": {
            "columnMatch": "latency_timeline",
            "formatter": 21,
            "formatOptions": {
              "palette": "purple"
            },
            "tooltipFormat": {
              "tooltip": "Average read or write IO latency over selected time range"
            }
          },
          "hivesContent": {
            "columnMatch": "grouper",
            "formatter": 18,
            "formatOptions": {
              "thresholdsOptions": "icons",
              "thresholdsGrid": [
                {
                  "operator": "is Empty",
                  "representation": "Blank",
                  "text": "{0}{1}"
                },
                {
                  "operator": "Default",
                  "thresholdValue": null,
                  "representation": "ResourceFlat",
                  "text": "{0}{1}"
                }
              ]
            }
          },
          "nodeIdField": "managed_instance_name",
          "graphOrientation": 3,
          "showOrientationToggles": false,
          "nodeSize": null,
          "staticNodeSize": 150,
          "colorSettings": {
            "nodeColorField": "latency",
            "type": 4,
            "heatmapPalette": "greenBlue",
            "heatmapMin": null,
            "heatmapMax": null,
            "emptyValueColor": "gray"
          },
          "groupByField": "grouper",
          "hivesMargin": 5
        }
      },
      "conditionalVisibility": {
        "parameterName": "ioMetric",
        "comparison": "isEqualTo",
        "value": "latency"
      },
      "name": "storage_io_latency_heatmap"
    }
  ],
  "$schema": "https://github.com/Microsoft/Application-Insights-Workbooks/blob/master/schema/workbook.json"
}