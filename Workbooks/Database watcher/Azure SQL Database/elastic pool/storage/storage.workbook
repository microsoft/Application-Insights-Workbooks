{
  "version": "Notebook/1.0",
  "items": [
    {
      "type": 3,
      "content": {
        "version": "KqlItem/1.0",
        "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"let metric = datatable(key:int, metric_name:string, tile_ordinal:int) [\\r\\n1, \\\"Data\\\", 1,\\r\\n1, \\\"Tempdb data\\\", 2,\\r\\n1, \\\"Tempdb log\\\", 3,\\r\\n1, \\\"Local storage\\\", 4\\r\\n];\\r\\nlet last_sample = sqldb_elastic_pool_storage_utilization\\r\\n| where sample_time_utc between (\\r\\n                                iif(({timeRange:end} - {timeRange:start}) <= 1h, ({timeRange:start} - 1h), {timeRange:start})\\r\\n                                ..\\r\\n                                iif(({timeRange:end} - {timeRange:start}) <= 1h, ({timeRange:end} + 1h), {timeRange:end})\\r\\n                                ) // Expand the range if selected range is shorter than the least frequent collection interval (1h)\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| top 1 by sample_time_utc desc\\r\\n| extend elastic_pool_data_max_size_mb = iif({isHyperscaleElasticPool} == 1 and isnull(elastic_pool_data_max_size_mb), tolong(1024*1024*100), elastic_pool_data_max_size_mb)\\r\\n| project key = int(1), last_data_size_used_ratio = toreal(elastic_pool_data_size_used_mb) / toreal(elastic_pool_data_max_size_mb),\\r\\n                        last_tempdb_data_size_used_ratio = toreal(tempdb_data_size_used_mb) / toreal(tempdb_data_max_size_mb), \\r\\n                        last_tempdb_log_size_used_ratio = toreal(tempdb_log_size_used_mb) / toreal(tempdb_log_max_size_mb),  \\r\\n                        last_local_storage_size_ratio = toreal(used_local_storage_size_mb) / toreal(max_local_storage_size_mb)\\r\\n| join kind=inner metric on key\\r\\n| extend metric_value = case(\\r\\n                            metric_name == \\\"Data\\\", last_data_size_used_ratio,\\r\\n                            metric_name == \\\"Tempdb data\\\", last_tempdb_data_size_used_ratio,\\r\\n                            metric_name == \\\"Tempdb log\\\", last_tempdb_log_size_used_ratio,\\r\\n                            metric_name == \\\"Local storage\\\", last_local_storage_size_ratio,\\r\\n                            real(null)\\r\\n                            )\\r\\n| summarize last_metric_value = max(metric_value) by metric_name;\\r\\nsqldb_elastic_pool_storage_utilization\\r\\n| where sample_time_utc between (\\r\\n                                iif(({timeRange:end} - {timeRange:start}) <= 1h, ({timeRange:start} - 1h), {timeRange:start})\\r\\n                                ..\\r\\n                                iif(({timeRange:end} - {timeRange:start}) <= 1h, ({timeRange:end} + 1h), {timeRange:end})\\r\\n                                ) // Expand the range if selected range is shorter than the least frequent collection interval (1h)\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| extend key = int(1)\\r\\n| join kind=inner metric on key\\r\\n| extend elastic_pool_data_max_size_mb = iif({isHyperscaleElasticPool} == 1 and isnull(elastic_pool_data_max_size_mb), tolong(1024*1024*100), elastic_pool_data_max_size_mb)\\r\\n| project key, metric_name, sample_time_utc, \\r\\n          data_size_used_ratio = toreal(elastic_pool_data_size_used_mb) / toreal(elastic_pool_data_max_size_mb), \\r\\n          tempdb_data_size_used_ratio = toreal(tempdb_data_size_used_mb) / toreal(tempdb_data_max_size_mb), \\r\\n          tempdb_log_size_used_ratio = toreal(tempdb_log_size_used_mb) / toreal(tempdb_log_max_size_mb), \\r\\n          local_storage_size_ratio = toreal(used_local_storage_size_mb) / toreal(max_local_storage_size_mb),\\r\\n          tile_ordinal\\r\\n| extend metric_value = case(\\r\\n                            metric_name == \\\"Data\\\", data_size_used_ratio,\\r\\n                            metric_name == \\\"Tempdb data\\\", tempdb_data_size_used_ratio,\\r\\n                            metric_name == \\\"Tempdb log\\\", tempdb_log_size_used_ratio,\\r\\n                            metric_name == \\\"Local storage\\\", local_storage_size_ratio,\\r\\n                            real(null)\\r\\n                            )\\r\\n| make-series metric_value = max(metric_value) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by metric_name, key, tile_ordinal\\r\\n| join kind=inner last_sample on metric_name\\r\\n| project sample_time_utc, metric_value, metric_name, last_metric_value, tile_ordinal\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
        "size": 3,
        "aggregation": 5,
        "showAnalytics": true,
        "title": "Storage consumption",
        "noDataMessage": "There is no data for specified parameters.",
        "queryType": 9,
        "visualization": "tiles",
        "tileSettings": {
          "titleContent": {
            "columnMatch": "metric_name",
            "formatter": 1,
            "tooltipFormat": {
              "tooltip": "Percentage of maximum size. For more information, see Storage consumption details."
            }
          },
          "rightContent": {
            "columnMatch": "last_metric_value",
            "formatter": 12,
            "formatOptions": {
              "min": 0,
              "max": 1,
              "palette": "greenRed"
            },
            "numberFormat": {
              "unit": 0,
              "options": {
                "style": "percent",
                "minimumFractionDigits": 2
              }
            }
          },
          "secondaryContent": {
            "columnMatch": "metric_value",
            "formatter": 9,
            "formatOptions": {
              "min": 0,
              "max": 1,
              "palette": "greenRed"
            },
            "tooltipFormat": {
              "tooltip": "Storage consumption trend"
            }
          },
          "showBorder": false,
          "sortCriteriaField": "tile_ordinal",
          "sortOrderField": 1
        },
        "graphSettings": {
          "type": 0
        },
        "chartSettings": {
          "showLegend": true,
          "seriesLabelSettings": [
            {
              "seriesName": "Maximum query store",
              "color": "redBright"
            },
            {
              "seriesName": "Persistent version store",
              "color": "orange"
            },
            {
              "seriesName": "Used query store",
              "color": "green"
            },
            {
              "seriesName": "Online index version store",
              "color": "pink"
            },
            {
              "seriesName": "Hyperscale RBPEX",
              "color": "blue"
            }
          ],
          "showDataPoints": true,
          "ySettings": {
            "numberFormatSettings": {
              "unit": 0,
              "options": {
                "style": "percent",
                "useGrouping": true,
                "maximumFractionDigits": 2
              }
            }
          }
        }
      },
      "name": "storage_consumption"
    },
    {
      "type": 12,
      "content": {
        "version": "NotebookGroup/1.0",
        "groupType": "editable",
        "title": "Storage consumption details",
        "expandable": true,
        "items": [
          {
            "type": 1,
            "content": {
              "json": "Metrics on these charts describe storage space consumption in data and transaction log files for this elastic pool and for the `tempdb` database of the same database engine instance. Data is collected from [sys.database_files](https://go.microsoft.com/fwlink/?linkid=2198860), [sys.dm_os_performance_counters](https://go.microsoft.com/fwlink/?linkid=2198647), and several other DMVs."
            },
            "conditionalVisibility": {
              "parameterName": "showDescriptions",
              "comparison": "isEqualTo",
              "value": "true"
            },
            "name": "storage_utilization_details_help"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"datatable(key:int, metric_name:string) [\\r\\n1, \\\"Used data\\\",\\r\\n1, \\\"Allocated data\\\"\\r\\n]\\r\\n| join kind=inner\\r\\n(\\r\\nsqldb_elastic_pool_storage_utilization\\r\\n| where sample_time_utc between ({timeRange:start} .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| extend key = int(1)\\r\\n) on key\\r\\n| project metric_name, sample_time_utc, elastic_pool_data_size_used_mb, elastic_pool_allocated_storage_size_mb\\r\\n| extend metric = case(\\r\\n                      metric_name == \\\"Used data\\\", elastic_pool_data_size_used_mb,\\r\\n                      metric_name == \\\"Allocated data\\\", elastic_pool_allocated_storage_size_mb,\\r\\n                      long(null)\\r\\n                      )\\r\\n| make-series metric = max(metric) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by metric_name\\r\\n| project metric_name, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Data storage",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "tileSettings": {
                "titleContent": {
                  "columnMatch": "metric_name",
                  "formatter": 1
                },
                "rightContent": {
                  "columnMatch": "metric"
                },
                "showBorder": false
              },
              "graphSettings": {
                "type": 0
              },
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Allocated data",
                    "color": "blue"
                  },
                  {
                    "seriesName": "Used data",
                    "color": "green"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 4,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "customWidth": "33",
            "name": "data_storage"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"datatable(key:int, metric_name:string) [\\r\\n1, \\\"Used tempdb data\\\",\\r\\n1, \\\"Allocated tempdb data\\\"\\r\\n]\\r\\n| join kind=inner\\r\\n(\\r\\nsqldb_elastic_pool_storage_utilization\\r\\n| where sample_time_utc between ({timeRange:start} .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| extend key = int(1)\\r\\n) on key\\r\\n| project metric_name, sample_time_utc, tempdb_data_size_used_mb, tempdb_data_size_allocated_mb\\r\\n| extend metric = case(\\r\\n                      metric_name == \\\"Used tempdb data\\\", tempdb_data_size_used_mb,\\r\\n                      metric_name == \\\"Allocated tempdb data\\\", tempdb_data_size_allocated_mb,\\r\\n                      decimal(null)\\r\\n                      )\\r\\n| make-series metric = max(metric) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by metric_name\\r\\n| project metric_name, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Tempdb data storage",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "tileSettings": {
                "titleContent": {
                  "columnMatch": "metric_name",
                  "formatter": 1
                },
                "rightContent": {
                  "columnMatch": "metric"
                },
                "showBorder": false
              },
              "graphSettings": {
                "type": 0
              },
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Allocated tempdb data",
                    "color": "blue"
                  },
                  {
                    "seriesName": "Used tempdb data",
                    "color": "green"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 4,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "customWidth": "33",
            "name": "tempdb_data_storage"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"datatable(key:int, metric_name:string) [\\r\\n1, \\\"Used tempdb log\\\",\\r\\n1, \\\"Allocated tempdb log\\\"\\r\\n]\\r\\n| join kind=inner\\r\\n(\\r\\nsqldb_elastic_pool_storage_utilization\\r\\n| where sample_time_utc between ({timeRange:start} .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| extend key = int(1)\\r\\n) on key\\r\\n| project metric_name, sample_time_utc, tempdb_log_size_used_mb, tempdb_log_size_allocated_mb\\r\\n| extend metric = case(\\r\\n                      metric_name == \\\"Used tempdb log\\\", tempdb_log_size_used_mb,\\r\\n                      metric_name == \\\"Allocated tempdb log\\\", tempdb_log_size_allocated_mb,\\r\\n                      decimal(null)\\r\\n                      )\\r\\n| make-series metric = max(metric) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain} by metric_name\\r\\n| project metric_name, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Tempdb transaction log storage",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "tileSettings": {
                "titleContent": {
                  "columnMatch": "metric_name",
                  "formatter": 1
                },
                "rightContent": {
                  "columnMatch": "metric"
                },
                "showBorder": false
              },
              "graphSettings": {
                "type": 0
              },
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Allocated tempdb log",
                    "color": "blue"
                  },
                  {
                    "seriesName": "Used tempdb log",
                    "color": "green"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 4,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "customWidth": "33",
            "name": "tempdb_log_storage"
          }
        ]
      },
      "name": "storage_consumption_details_group"
    },
    {
      "type": 12,
      "content": {
        "version": "NotebookGroup/1.0",
        "groupType": "editable",
        "title": "Storage IO statistics",
        "expandable": true,
        "expanded": true,
        "items": [
          {
            "type": 1,
            "content": {
              "json": "Metrics on these charts describe aggregate storage IO statistics including IOPS, throughput, and latency for all databases in this elastic pool and for the `tempdb` database of the same database engine instance. Separate charts are provided for reads and writes. Data is collected from [sys.dm_io_virtual_file_stats()](https://go.microsoft.com/fwlink/?linkid=2198746)."
            },
            "conditionalVisibility": {
              "parameterName": "showDescriptions",
              "comparison": "isEqualTo",
              "value": "true"
            },
            "name": "storage_io_stats_help"
          },
          {
            "type": 11,
            "content": {
              "version": "LinkItem/1.0",
              "style": "tabs",
              "links": [
                {
                  "id": "ca53e0e9-7129-4b85-b842-35b42d1ab5c4",
                  "cellValue": "storageTabName",
                  "linkTarget": "parameter",
                  "linkLabel": "IOPS",
                  "subTarget": "IOPS",
                  "style": "link",
                  "linkIsContextBlade": true
                },
                {
                  "id": "8b5fd7cb-85e0-4912-aaf3-de7c1b10d7d4",
                  "cellValue": "storageTabName",
                  "linkTarget": "parameter",
                  "linkLabel": "Throughput",
                  "subTarget": "Throughput",
                  "style": "link"
                },
                {
                  "id": "f6a93425-3f64-42f3-8715-4d59849ff645",
                  "cellValue": "storageTabName",
                  "linkTarget": "parameter",
                  "linkLabel": "Latency",
                  "subTarget": "Latency",
                  "style": "link"
                }
              ]
            },
            "name": "storage_io_stats_navigation"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"sqldb_elastic_pool_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| project sample_time_utc, anchor_database_replica_id, file_id, file_type, instance_database_id, num_of_reads, io_snapshot_sample_ms\\r\\n| sort by instance_database_id asc, anchor_database_replica_id, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_num_of_reads = iif(num_of_reads >= prev(num_of_reads) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id) and anchor_database_replica_id == prev(anchor_database_replica_id), num_of_reads - prev(num_of_reads), long(null)),\\r\\n         delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| extend iops = toreal(delta_num_of_reads) / delta_io_snapshot_sample_ms * 1000\\r\\n| summarize iops = sum(iops) by sample_time_utc, file_type, io_instance_database_id = case(instance_database_id in (0,2), instance_database_id, int(null)) // aggregate all user database IO\\r\\n| project sample_time_utc, file_label = strcat(iif(io_instance_database_id == 2, \\\"tempdb | \\\", \\\"\\\"), file_type), iops\\r\\n| make-series metric = max(iops) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain}/{grainFactor} by file_label\\r\\n| project file_label, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Read IOPS",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Data",
                    "color": "blue"
                  },
                  {
                    "seriesName": "Log",
                    "color": "green"
                  },
                  {
                    "seriesName": "tempdb | Data",
                    "color": "blueDark"
                  },
                  {
                    "seriesName": "tempdb | Log",
                    "color": "greenDark"
                  },
                  {
                    "seriesName": "RBPEX",
                    "color": "turquoise"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 0,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true
                    }
                  }
                }
              }
            },
            "conditionalVisibility": {
              "parameterName": "storageTabName",
              "comparison": "isEqualTo",
              "value": "IOPS"
            },
            "name": "read_iops"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"sqldb_elastic_pool_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| project sample_time_utc, anchor_database_replica_id, file_id, file_type, instance_database_id, num_of_writes, io_snapshot_sample_ms\\r\\n| sort by instance_database_id asc, anchor_database_replica_id asc, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_num_of_writes = iif(num_of_writes >= prev(num_of_writes) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id) and anchor_database_replica_id == prev(anchor_database_replica_id), num_of_writes - prev(num_of_writes), long(null)),\\r\\n         delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| extend iops = toreal(delta_num_of_writes) / delta_io_snapshot_sample_ms * 1000\\r\\n| summarize iops = sum(iops) by sample_time_utc, file_type, io_instance_database_id = case(instance_database_id in (0,2), instance_database_id, int(null))\\r\\n| project sample_time_utc, file_label = strcat(iif(io_instance_database_id == 2, \\\"tempdb | \\\", \\\"\\\"), file_type), iops\\r\\n| make-series metric = max(iops) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain}/{grainFactor} by file_label\\r\\n| project file_label, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Write IOPS",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "tempdb | Log",
                    "color": "orange"
                  },
                  {
                    "seriesName": "Log",
                    "color": "yellow"
                  },
                  {
                    "seriesName": "Data",
                    "color": "red"
                  },
                  {
                    "seriesName": "tempdb | Data",
                    "color": "redDark"
                  },
                  {
                    "seriesName": "RBPEX",
                    "color": "turquoise"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 0,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true
                    }
                  }
                }
              }
            },
            "conditionalVisibility": {
              "parameterName": "storageTabName",
              "comparison": "isEqualTo",
              "value": "IOPS"
            },
            "name": "write_iops"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"sqldb_elastic_pool_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| project sample_time_utc, anchor_database_replica_id, file_id, file_type, instance_database_id, num_of_bytes_read, io_snapshot_sample_ms\\r\\n| sort by instance_database_id asc, anchor_database_replica_id asc, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_num_of_bytes_read = iif(num_of_bytes_read >= prev(num_of_bytes_read) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id) and anchor_database_replica_id == prev(anchor_database_replica_id), num_of_bytes_read - prev(num_of_bytes_read), long(null)),\\r\\n         delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize delta_num_of_bytes_read = sum(delta_num_of_bytes_read) by sample_time_utc, file_type, io_instance_database_id = case(instance_database_id in (0,2), instance_database_id, int(null)), delta_io_snapshot_sample_ms\\r\\n| project sample_time_utc, file_label = strcat(iif(io_instance_database_id == 2, \\\"tempdb | \\\", \\\"\\\"), file_type), delta_read_throughput = toreal(delta_num_of_bytes_read) / delta_io_snapshot_sample_ms * 1000\\r\\n| make-series metric = max(delta_read_throughput) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain}/{grainFactor} by file_label\\r\\n| project file_label, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Read throughput",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Data",
                    "color": "blue"
                  },
                  {
                    "seriesName": "Log",
                    "color": "green"
                  },
                  {
                    "seriesName": "tempdb | Data",
                    "color": "blueDark"
                  },
                  {
                    "seriesName": "tempdb | Log",
                    "color": "greenDark"
                  },
                  {
                    "seriesName": "RBPEX",
                    "color": "turquoise"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 11,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "conditionalVisibility": {
              "parameterName": "storageTabName",
              "comparison": "isEqualTo",
              "value": "Throughput"
            },
            "name": "read_throughput"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"sqldb_elastic_pool_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| project sample_time_utc, anchor_database_replica_id, file_id, file_type, instance_database_id, num_of_bytes_written, io_snapshot_sample_ms\\r\\n| sort by instance_database_id asc, anchor_database_replica_id asc, file_id asc, sample_time_utc asc, io_snapshot_sample_ms asc\\r\\n| extend delta_num_of_bytes_written = iif(num_of_bytes_written >= prev(num_of_bytes_written) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id) and anchor_database_replica_id == prev(anchor_database_replica_id), num_of_bytes_written - prev(num_of_bytes_written), long(null)),\\r\\n         delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize delta_num_of_bytes_written = sum(delta_num_of_bytes_written) by sample_time_utc, file_type, io_instance_database_id = case(instance_database_id in (0,2), instance_database_id, int(null)), delta_io_snapshot_sample_ms\\r\\n| project sample_time_utc, file_label = strcat(iif(io_instance_database_id == 2, \\\"tempdb | \\\", \\\"\\\"), file_type), delta_write_throughput = toreal(delta_num_of_bytes_written) / delta_io_snapshot_sample_ms * 1000\\r\\n| make-series metric = max(delta_write_throughput) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain}/{grainFactor} by file_label\\r\\n| project file_label, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Write throughput",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "tempdb | Log",
                    "color": "orange"
                  },
                  {
                    "seriesName": "Data",
                    "color": "red"
                  },
                  {
                    "seriesName": "Log",
                    "color": "yellow"
                  },
                  {
                    "seriesName": "tempdb | Data",
                    "color": "redDark"
                  },
                  {
                    "seriesName": "RBPEX",
                    "color": "turquoise"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 11,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "conditionalVisibility": {
              "parameterName": "storageTabName",
              "comparison": "isEqualTo",
              "value": "Throughput"
            },
            "name": "write_throughput"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"sqldb_elastic_pool_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| project sample_time_utc, anchor_database_replica_id, file_id, file_type, instance_database_id, num_of_reads, io_stall_read_ms, io_snapshot_sample_ms\\r\\n| sort by instance_database_id asc, anchor_database_replica_id asc, file_id asc, sample_time_utc asc\\r\\n| extend delta_num_of_reads = iif(num_of_reads >= prev(num_of_reads) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id) and anchor_database_replica_id == prev(anchor_database_replica_id), num_of_reads - prev(num_of_reads), long(null)),\\r\\n         delta_io_stall_read_ms = iif(io_stall_read_ms >= prev(io_stall_read_ms) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id), io_stall_read_ms - prev(io_stall_read_ms), long(null)),\\r\\n         delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize delta_num_of_reads = sum(delta_num_of_reads),\\r\\n            delta_io_stall_read_ms = sum(delta_io_stall_read_ms)\\r\\n  by sample_time_utc, file_type, io_instance_database_id = case(instance_database_id in (0,2), instance_database_id, int(null))\\r\\n| project sample_time_utc, file_label = strcat(iif(io_instance_database_id == 2, \\\"tempdb | \\\", \\\"\\\"), file_type), delta_read_latency_ms = iif(delta_num_of_reads != 0, toreal(delta_io_stall_read_ms) / delta_num_of_reads, real(null))\\r\\n| make-series metric = max(delta_read_latency_ms) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain}/{grainFactor} by file_label\\r\\n| project file_label, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Read latency",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Log",
                    "color": "green"
                  },
                  {
                    "seriesName": "Data",
                    "color": "blue"
                  },
                  {
                    "seriesName": "tempdb | Data",
                    "color": "blueDark"
                  },
                  {
                    "seriesName": "tempdb | Log",
                    "color": "greenDark"
                  },
                  {
                    "seriesName": "RBPEX",
                    "color": "turquoise"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 23,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "minimumFractionDigits": 2,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "conditionalVisibility": {
              "parameterName": "storageTabName",
              "comparison": "isEqualTo",
              "value": "Latency"
            },
            "name": "read_latency"
          },
          {
            "type": 3,
            "content": {
              "version": "KqlItem/1.0",
              "query": "{\"version\":\"AzureDataExplorerQuery/1.0\",\"queryText\":\"sqldb_elastic_pool_storage_io\\r\\n| where sample_time_utc between (({timeRange:start} - {timeRange:grain}) .. {timeRange:end})\\r\\n| where logical_server_name =~ @\\\"{serverName}\\\"\\r\\n| where elastic_pool_name == @\\\"{elasticPoolName}\\\"\\r\\n| where ({haReplica} and replica_type == \\\"HA secondary\\\") or (not ({haReplica}) and replica_type != \\\"HA secondary\\\")\\r\\n| project sample_time_utc, anchor_database_replica_id, file_id, file_type, instance_database_id, num_of_writes, io_stall_write_ms, io_snapshot_sample_ms\\r\\n| sort by instance_database_id asc, anchor_database_replica_id asc, file_id asc, sample_time_utc asc\\r\\n| extend delta_num_of_writes = iif(num_of_writes >= prev(num_of_writes) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id) and anchor_database_replica_id == prev(anchor_database_replica_id), num_of_writes - prev(num_of_writes), long(null)),\\r\\n         delta_io_stall_write_ms = iif(io_stall_write_ms >= prev(io_stall_write_ms) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id), io_stall_write_ms - prev(io_stall_write_ms), long(null)),\\r\\n         delta_io_snapshot_sample_ms = iif(io_snapshot_sample_ms >= prev(io_snapshot_sample_ms) and instance_database_id == prev(instance_database_id) and file_id == prev(file_id), io_snapshot_sample_ms - prev(io_snapshot_sample_ms), long(null))\\r\\n| where isnotempty(delta_io_snapshot_sample_ms)\\r\\n| summarize delta_num_of_writes = sum(delta_num_of_writes),\\r\\n            delta_io_stall_write_ms = sum(delta_io_stall_write_ms)\\r\\n  by sample_time_utc, file_type, io_instance_database_id = case(instance_database_id in (0,2), instance_database_id, int(null))\\r\\n| project sample_time_utc, file_label = strcat(iif(io_instance_database_id == 2, \\\"tempdb | \\\", \\\"\\\"), file_type), delta_write_latency_ms = iif(delta_num_of_writes != 0, toreal(delta_io_stall_write_ms) / delta_num_of_writes, real(null))\\r\\n| make-series metric = max(delta_write_latency_ms) default = long(null) on sample_time_utc from {timeRange:start} to {timeRange:end} step {timeRange:grain}/{grainFactor} by file_label\\r\\n| project file_label, metric = series_fill_forward(series_fill_linear(metric, int(null), false)), sample_time_utc\",\"clusterName\":\"{adxClusterUri}\",\"databaseName\":\"{adxDatabase}\"}",
              "size": 1,
              "aggregation": 5,
              "showAnalytics": true,
              "title": "Write latency",
              "noDataMessage": "There is no data for specified parameters.",
              "timeBrushParameterName": "timeRange",
              "queryType": 9,
              "visualization": "linechart",
              "chartSettings": {
                "showLegend": true,
                "seriesLabelSettings": [
                  {
                    "seriesName": "Log",
                    "color": "yellow"
                  },
                  {
                    "seriesName": "Data",
                    "color": "red"
                  },
                  {
                    "seriesName": "tempdb | Log",
                    "color": "orange"
                  },
                  {
                    "seriesName": "tempdb | Data",
                    "color": "redDark"
                  },
                  {
                    "seriesName": "RBPEX",
                    "color": "turquoise"
                  }
                ],
                "ySettings": {
                  "numberFormatSettings": {
                    "unit": 23,
                    "options": {
                      "style": "decimal",
                      "useGrouping": true,
                      "minimumFractionDigits": 2,
                      "maximumFractionDigits": 2
                    }
                  }
                }
              }
            },
            "conditionalVisibility": {
              "parameterName": "storageTabName",
              "comparison": "isEqualTo",
              "value": "Latency"
            },
            "name": "write_latency"
          }
        ]
      },
      "name": "storage_io_stats_group"
    }
  ],
  "$schema": "https://github.com/Microsoft/Application-Insights-Workbooks/blob/master/schema/workbook.json"
}