{
  "version": "Notebook/1.0",
  "items": [
    {
      "type": 1,
      "content": {
        "json": "# Feature evaluation via A/B testing -- monitoring and results\r\n---\r\n\r\nThis workbook is designed for Azure AppConfig A/B tests. \r\n\r\n- Select your log analytics workspace where your app telemetry lives.\r\n- Select a recently tested feature to explore.\r\n- Choose an experiment iteration (ETag) and control (baseline) variant to review how each treatment (new) variant compares across your configured metrics."
      },
      "customWidth": "70",
      "name": "text - intro",
      "styleSettings": {
        "padding": "3px"
      }
    },
    {
      "type": 9,
      "content": {
        "version": "KqlParameterItem/1.0",
        "crossComponentResources": [
          "{Source}"
        ],
        "parameters": [
          {
            "id": "9a6e815b-22c5-4fd1-a260-9ed52c977ffa",
            "version": "KqlParameterItem/1.0",
            "name": "Source",
            "type": 5,
            "description": "Select the log analytics workspace containing your application experiment data",
            "isRequired": true,
            "query": "where type == \"microsoft.operationalinsights/workspaces\"\r\n| project id\r\n| order by id contains \"exp\" desc",
            "crossComponentResources": [
              "value::all"
            ],
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "timeContext": {
              "durationMs": 86400000
            },
            "queryType": 1,
            "resourceType": "microsoft.resourcegraph/resources"
          },
          {
            "id": "1fa73eb5-2b91-4865-871c-b74db05d7bd0",
            "version": "KqlParameterItem/1.0",
            "name": "_feature",
            "label": "Feature",
            "type": 2,
            "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated\r\n| summarize start = min(TimeGenerated), end = max(TimeGenerated) by Feature\r\n| order by end desc\r\n| project Feature",
            "crossComponentResources": [
              "{Source}"
            ],
            "typeSettings": {
              "additionalResourceOptions": []
            },
            "queryType": 0,
            "resourceType": "microsoft.operationalinsights/workspaces",
            "value": null
          },
          {
            "id": "e4d37177-cb2c-4c72-b027-0a9c84dd2fd8",
            "version": "KqlParameterItem/1.0",
            "name": "_etag",
            "label": "ETag (experiment iteration)",
            "type": 2,
            "isRequired": true,
            "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), ETag = tostring(Properties.ETag), TimeGenerated\r\n| where \"{_feature}\"==\"\" or Feature ==\"{_feature}\"\r\n| summarize start = min(TimeGenerated), end = max(TimeGenerated) by ETag\r\n| order by end desc\r\n| project ETag, dateRange = strcat(format_datetime(start,'yyyy/MM/dd'),\" - \" , format_datetime(end,'yyyy/MM/dd'), \" (\", ETag,\")\"), start, end",
            "crossComponentResources": [
              "{Source}"
            ],
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "queryType": 0,
            "resourceType": "microsoft.operationalinsights/workspaces"
          },
          {
            "id": "39661f6f-e534-41f7-b529-feb382367773",
            "version": "KqlParameterItem/1.0",
            "name": "_control",
            "label": "Control Variant (baseline)",
            "type": 2,
            "isRequired": true,
            "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\"\r\n| where Properties.VariantAssignmentReason == \"Percentile\" and Properties.ETag == \"{_etag}\"\r\n| project Variant = tostring(Properties.Variant), TimeGenerated\r\n| summarize start = min(TimeGenerated), end = max(TimeGenerated) by Variant\r\n| order by end desc\r\n| project Variant",
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "queryType": 0,
            "resourceType": "microsoft.operationalinsights/workspaces",
            "value": "Original-gpt-4"
          }
        ],
        "style": "formVertical",
        "queryType": 0,
        "resourceType": "microsoft.operationalinsights/workspaces"
      },
      "customWidth": "30",
      "name": "parameters - preliminary source"
    },
    {
      "type": 3,
      "content": {
        "version": "KqlItem/1.0",
        "query": "AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, Variant = tostring(Properties.Variant), ETag = tostring(Properties.ETag), TargetId = tostring(Properties.TargetingId)\r\n| where \"{_feature}\" == \"\" or Feature == \"{_feature}\"\r\n| make-series AssignmentEvents = count() on TimeGenerated from ago(90d) to now()  step 6h  by Feature, ETag, Variant\r\n| project AssignmentEvents, Feature, ETag, Variant\r\n| join kind = inner (\r\nAppEvents\r\n| where TimeGenerated> ago(90d)\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, Variant = tostring(Properties.Variant), ETag = tostring(Properties.ETag), TargetId = tostring(Properties.TargetingId)\r\n| where \"{_feature}\" == \"\" or Feature == \"{_feature}\"\r\n| summarize EarliestAssignment = min(TimeGenerated), MostRecentAssignment = max(TimeGenerated), TargetingIdEstimatedCount = dcount(TargetId) by Feature, ETag, Variant\r\n| extend DaysSinceLastAssignment = datetime_diff('Day',now(), MostRecentAssignment) ) on Feature, ETag, Variant\r\n| order by DaysSinceLastAssignment asc\r\n| project Feature, ETag, Variant, EarliestAssignment, MostRecentAssignment, AssignmentEvents, TargetingIdEstimatedCount, DaysSinceLastAssignment, ID = strcat(ETag, Variant), PARENT = ETag\r\n| union (AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, ETag = tostring(Properties.ETag), TargetId = tostring(Properties.TargetingId)\r\n| where \"{_feature}\" == \"\" or Feature == \"{_feature}\"\r\n| make-series AssignmentEvents = count() on TimeGenerated from ago(90d) to now()  step 6h  by Feature, ETag\r\n| project AssignmentEvents, Feature, ETag\r\n| join kind = inner (\r\nAppEvents\r\n| where TimeGenerated> ago(90d)\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, ETag = tostring(Properties.ETag), Variant = tostring(Properties.Variant), TargetId = tostring(Properties.TargetingId)\r\n| where \"{_feature}\" == \"\" or Feature == \"{_feature}\"\r\n| summarize Variant = strcat(\"(\",dcount(Variant),\") Variants\"), EarliestAssignment = min(TimeGenerated), MostRecentAssignment = max(TimeGenerated), TargetingIdEstimatedCount = dcount(TargetId) by Feature, ETag\r\n| extend DaysSinceLastAssignment = datetime_diff('Day',now(), MostRecentAssignment) ) on Feature, ETag\r\n| order by DaysSinceLastAssignment asc\r\n| project Feature, ETag, Variant, EarliestAssignment, MostRecentAssignment, AssignmentEvents, TargetingIdEstimatedCount, DaysSinceLastAssignment, ID = ETag, PARENT = Feature)\r\n| union (AppEvents\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), TimeGenerated, TargetId = tostring(Properties.TargetingId)\r\n| where \"{_feature}\" == \"\" or Feature == \"{_feature}\"\r\n| make-series AssignmentEvents = count() on TimeGenerated from ago(90d) to now()  step 6h  by Feature\r\n| project AssignmentEvents, Feature\r\n| join kind = inner (\r\nAppEvents\r\n| where TimeGenerated> ago(90d)\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\"\r\n| project Feature = tostring(Properties.FeatureName), ETag = tostring(Properties.ETag),  Variant = tostring(Properties.Variant), TimeGenerated, TargetId = tostring(Properties.TargetingId)\r\n| where \"{_feature}\" == \"\" or Feature == \"{_feature}\"\r\n| summarize EarliestAssignment = min(TimeGenerated), ETag = strcat(\"(\",dcount(ETag),\") ETags\"), Variant = strcat(\"(\",dcount(Variant),\") Variants\"), MostRecentAssignment = max(TimeGenerated), TargetingIdEstimatedCount = dcount(TargetId) by Feature\r\n| extend DaysSinceLastAssignment = datetime_diff('Day',now(), MostRecentAssignment) ) on Feature\r\n| order by DaysSinceLastAssignment asc\r\n| project Feature, ETag, Variant, DaysSinceLastAssignment,  EarliestAssignment, MostRecentAssignment, AssignmentEvents, TargetingIdEstimatedCount, ID = Feature, PARENT = \"\")\r\n",
        "size": 3,
        "exportFieldName": "Feature",
        "exportParameterName": "Feature",
        "queryType": 0,
        "resourceType": "microsoft.operationalinsights/workspaces",
        "crossComponentResources": [
          "{Source}"
        ],
        "visualization": "table",
        "gridSettings": {
          "formatters": [
            {
              "columnMatch": "Feature",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "icons",
                "thresholdsGrid": [
                  {
                    "sourceColumn": "DaysSinceLastAssignment",
                    "operator": "<=",
                    "thresholdValue": "1",
                    "representation": "pending",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "Recent random assignments to this feature's variants"
                    }
                  },
                  {
                    "sourceColumn": "DaysSinceLastAssignment",
                    "operator": ">",
                    "thresholdValue": "1",
                    "representation": "stopped",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "No recent random assignments to this feature"
                    }
                  },
                  {
                    "sourceColumn": "DaysSinceLastAssignment",
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "success",
                    "text": "{0}{1}"
                  }
                ]
              }
            },
            {
              "columnMatch": "ETag",
              "formatter": 0,
              "formatOptions": {
                "customColumnWidthSetting": "15ch"
              }
            },
            {
              "columnMatch": "AssignmentEvents",
              "formatter": 9,
              "formatOptions": {
                "palette": "blue"
              }
            },
            {
              "columnMatch": "TargetingIdEstimatedCount",
              "formatter": 4,
              "formatOptions": {
                "min": 0,
                "max": 10000,
                "palette": "blue"
              }
            },
            {
              "columnMatch": "DaysSinceLastAssignment",
              "formatter": 5
            },
            {
              "columnMatch": "ID",
              "formatter": 5
            },
            {
              "columnMatch": "PARENT",
              "formatter": 5
            },
            {
              "columnMatch": "count_",
              "formatter": 9,
              "formatOptions": {
                "palette": "blue"
              }
            }
          ],
          "hierarchySettings": {
            "idColumn": "ID",
            "parentColumn": "PARENT",
            "treeType": 0,
            "expanderColumn": "Feature",
            "expandTopLevel": false
          },
          "labelSettings": [
            {
              "columnId": "EarliestAssignment",
              "label": "Earliest assignment"
            },
            {
              "columnId": "MostRecentAssignment",
              "label": "Most recent assignment"
            },
            {
              "columnId": "AssignmentEvents",
              "label": "Assignment volume (90d)"
            },
            {
              "columnId": "TargetingIdEstimatedCount",
              "label": "Sample size (approx)"
            }
          ]
        },
        "sortBy": [],
        "graphSettings": {
          "type": 0,
          "topContent": {
            "columnMatch": "Feature",
            "formatter": 1
          },
          "centerContent": {
            "columnMatch": "TargetingIdEstimatedCount",
            "formatter": 1,
            "numberFormat": {
              "unit": 17,
              "options": {
                "maximumSignificantDigits": 3,
                "maximumFractionDigits": 2
              }
            }
          }
        }
      },
      "customWidth": "100",
      "name": "query - feature, etag, variant assignments"
    },
    {
      "type": 1,
      "content": {
        "json": "### Most recent A/B results for treatment variants of Feature: **{_feature}**, with comparison against control variant: **{_control}**\r\n\r\n\r\nEach metric displays:\r\n-  assessed treatment effect: statistically significant effects are labeled as \"Improved\", \"Degraded\" or \"Changed\" depending on whether the effect direction matches the metric's configured direction of improvement.\r\n- Effect estimated size, as a % lift/drop from control variant.\r\n- Estimate of the margin of error on the effect estimate. Each metric measurement is from a limited sample of potentially noisy data, which guarantee the estimate is not what you'd observe if the feature were exposed to all users. The margin of error gives an approximate bound for how far the estimated effect from this experiment may be from the true effect. Running an experiment for longer duration (or increased traffic allocation) generally lowers the margin of error.\r\n- Control and Treatment metric values: the actual metric value in each variant.\r\n- Interpretability risk level: metrics with very low sample size or other data quality issues can be unreliable. If a metric is flagged with high interpretability risk, we have detected a data quality issue on that metric which prevents it's use for a decision on feature evaluation. More reliable data is needed -- either through higher sample size, or by refining the telemetry logging which contributes to the metric. "
      },
      "name": "text - metric table explainer"
    },
    {
      "type": 9,
      "content": {
        "version": "KqlParameterItem/1.0",
        "parameters": [
          {
            "id": "ef6f6313-8917-4f38-97bf-e8048217cb23",
            "version": "KqlParameterItem/1.0",
            "name": "Metrics",
            "type": 2,
            "multiSelect": true,
            "quote": "'",
            "delimiter": ",",
            "query": "ComputeScorecardAB_LatestExperiment(feature_name=\"{_feature}\",control_variant=\"{_control}\", lookback=30d)\r\n| where MetricDisplayName != \"Sample size\"\r\n| distinct MetricDisplayName",
            "crossComponentResources": [
              "{Source}"
            ],
            "typeSettings": {
              "additionalResourceOptions": [
                "value::all"
              ],
              "selectAllValue": "all",
              "showDefault": false
            },
            "defaultValue": "value::all",
            "queryType": 0,
            "resourceType": "microsoft.operationalinsights/workspaces",
            "value": [
              "value::all"
            ]
          },
          {
            "id": "d953ebfa-a7df-4461-b0dc-9c668fc4a675",
            "version": "KqlParameterItem/1.0",
            "name": "AlphaThreshold",
            "label": "Strength of Evidence",
            "type": 2,
            "typeSettings": {
              "additionalResourceOptions": [],
              "showDefault": false
            },
            "jsonData": "[{\"label\":\"Highly Stat Sig\", \"value\":0.001},{\"label\": \"Stat Sig\",\"value\":0.05},{\"label\": \"All\",\"value\":1}]",
            "value": "0.001"
          },
          {
            "id": "73b6acec-2f3d-4df3-a027-98493402f258",
            "version": "KqlParameterItem/1.0",
            "name": "EffectType",
            "label": "Treatment Effect",
            "type": 2,
            "multiSelect": true,
            "quote": "'",
            "delimiter": ",",
            "typeSettings": {
              "additionalResourceOptions": [
                "value::all"
              ],
              "selectAllValue": "all",
              "showDefault": false
            },
            "jsonData": "[\"Changed\",\"Improved\",\"Degraded\",\"Inconclusive\"]",
            "defaultValue": "value::all"
          }
        ],
        "style": "pills",
        "queryType": 0,
        "resourceType": "microsoft.operationalinsights/workspaces"
      },
      "name": "parameters - metrics - Copy"
    },
    {
      "type": 3,
      "content": {
        "version": "KqlItem/1.0",
        "query": "let _start= toscalar(AppEvents\r\n| where TimeGenerated > ago(90d)\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\" and tostring(Properties.ETag)== \"{_etag}\"\r\n| summarize min(TimeGenerated));\r\nlet _end = toscalar(AppEvents\r\n| where TimeGenerated >= _start\r\n| where Name == \"FeatureEvaluation\" and Properties.VariantAssignmentReason==\"Percentile\" and tostring(Properties.ETag)== \"{_etag}\"\r\n| summarize max(TimeGenerated));\r\nlet _MostRecentScorecardResult = ComputeScorecardAB(etag = \"{_etag}\",control_variant=\"{_control}\", start_date = _start, end_date = _end );\r\nlet t = 2.0 ; //rough t score for margin of error\r\nlet buffer = 0.0000000001; // avoid zero denominator\r\nlet alpha_weak = 0.05;\r\n_MostRecentScorecardResult\r\n| where case('all' in ({Metrics}),true, MetricDisplayName in ({Metrics}) ) and case('all' in ({EffectType}), true, TreatmentEffect in ({EffectType})) and case(\"{AlphaThreshold}\" == \"\",true, PValue < todouble(\"{AlphaThreshold}\"))//  abs(ControlMetricValue) >= 0 and PValue < alpha_weak\r\n| extend EstimatedEffect = round(100*(TreatmentMetricValueNormalized - ControlMetricValueNormalized)/(ControlMetricValueNormalized+buffer),2), EstimateMarginOfError = max_of(0.01,round(iff(ControlCount*TreatmentCount > 900, 100* sqrt(pow(TreatmentStandardErrorNormalized,2)+ pow(ControlStandardErrorNormalized,2))*t/(ControlMetricValueNormalized+buffer), 100.0)),2), MetricDescription = iff(MetricDescription != \"NA\", MetricDescription,\"\")\r\n| extend Effect_Category = case(PValue >= alpha_weak ,0,\r\n(DesiredDirection ==\"Decrease\" and TreatmentMetricValue > ControlMetricValue) or (DesiredDirection==\"Increase\" and TreatmentMetricValue < ControlMetricValue),-2,\r\n(DesiredDirection ==\"Decrease\" and TreatmentMetricValue < ControlMetricValue) or (DesiredDirection==\"Increase\" and TreatmentMetricValue > ControlMetricValue), +2,\r\n+1)\r\n| extend SampleSize_RiskLevel = min_of(10,round(1+15/log2(min_of(TreatmentCount,ControlCount)))), SignalQuality_RiskLevel = min_of(10,iff(ControlStandardErrorNormalized*TreatmentStandardErrorNormalized==0,5.0, max_of(round(ControlStandardErrorNormalized/ControlMetricValueNormalized), round(TreatmentStandardErrorNormalized/TreatmentMetricValueNormalized)))), Insights= bag_pack(\"SufficientData\",iff(ControlCount*TreatmentCount < 900, \"Unhealthy. Low sample size\", \"OK\"), \"SignalClarity\",iff(ControlStandardErrorNormalized * TreatmentStandardErrorNormalized == 0 , \"Unhealthy. No variation: potential data quality issue\", iff(max_of(ControlStandardErrorNormalized/ControlMetricValueNormalized, TreatmentStandardErrorNormalized/TreatmentMetricValueNormalized) > 10, \"Unhealthy. Highly noisy signal\", \"OK\")))\r\n| extend Insight_RiskLevel = case(max_of(SignalQuality_RiskLevel, SampleSize_RiskLevel)>7, \"high\",max_of(SignalQuality_RiskLevel, SampleSize_RiskLevel)>4, \"moderate\",\"low\")\r\n| project MetricDisplayName, TreatmentVariant, TreatmentEffect, Effect_Estimate = strcat( iff(EstimatedEffect>0,\"+\",\"\"), EstimatedEffect,\"%\"), Estimate_MarginOfError = strcat(\"+/-\",EstimateMarginOfError,\"%\") , MetricKind, Control_Value = round(ControlMetricValue,3), Treatment_Value = round(TreatmentMetricValue,3), Interpretation_Warnings = Insight_RiskLevel, PValue ,Insights\r\n| order by TreatmentEffect asc",
        "size": 3,
        "title": "Metric movements, using {_control} as control.",
        "showExportToExcel": true,
        "queryType": 0,
        "resourceType": "microsoft.operationalinsights/workspaces",
        "crossComponentResources": [
          "{Source}"
        ],
        "gridSettings": {
          "formatters": [
            {
              "columnMatch": "MetricDisplayName",
              "formatter": 5
            },
            {
              "columnMatch": "TreatmentVariant",
              "formatter": 5
            },
            {
              "columnMatch": "TreatmentEffect",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "icons",
                "thresholdsGrid": [
                  {
                    "operator": "==",
                    "thresholdValue": "Improved",
                    "representation": "success",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "The metric shows a statistically better value (normalized by user count) in the treatment variant compared to selected control."
                    }
                  },
                  {
                    "operator": "==",
                    "thresholdValue": "Degraded",
                    "representation": "4",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "The metric shows a statistically worse value (normalized by user count) in the treatment variant compared to selected control."
                    }
                  },
                  {
                    "operator": "==",
                    "thresholdValue": "Changed",
                    "representation": "1",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "The metric value changed statistically significantly, but the desired direction isn't known for this metric."
                    }
                  },
                  {
                    "operator": "==",
                    "thresholdValue": "Inconclusive",
                    "representation": "Normal",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "The metric value is not statistically confirmed as different from control. More data may be required to compare these variants."
                    }
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": null,
                    "text": "{0}{1}"
                  }
                ]
              },
              "numberFormat": {
                "unit": 0,
                "options": {
                  "style": "decimal"
                }
              },
              "tooltipFormat": {
                "tooltip": "Is there a stat-sig change observed in the metric?"
              }
            },
            {
              "columnMatch": "Control_Value",
              "formatter": 0,
              "numberFormat": {
                "unit": 0,
                "options": {
                  "style": "decimal"
                }
              }
            },
            {
              "columnMatch": "Interpretation_Warnings",
              "formatter": 18,
              "formatOptions": {
                "thresholdsOptions": "icons",
                "thresholdsGrid": [
                  {
                    "operator": "==",
                    "thresholdValue": "moderate",
                    "representation": "Sev2",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "Metric has some issues that may impact it's interpretability. This may include: moderately low sample size, imbalance of sample size between variants, unexpectedly high or low variance."
                    }
                  },
                  {
                    "operator": "==",
                    "thresholdValue": "severe",
                    "representation": "Sev0",
                    "text": "{0}{1}",
                    "tooltipFormat": {
                      "tooltip": "Severe issues: higher quantity of data is required to trust this metric for decision"
                    }
                  },
                  {
                    "operator": "Default",
                    "thresholdValue": null,
                    "representation": "Sev4",
                    "text": "{0}{1}"
                  }
                ]
              }
            },
            {
              "columnMatch": "PValue",
              "formatter": 5
            },
            {
              "columnMatch": "Insights",
              "formatter": 5
            }
          ],
          "hierarchySettings": {
            "treeType": 1,
            "groupBy": [
              "MetricDisplayName"
            ],
            "expandTopLevel": true,
            "finalBy": "TreatmentVariant"
          },
          "labelSettings": [
            {
              "columnId": "MetricDisplayName",
              "label": "Metric"
            },
            {
              "columnId": "TreatmentEffect",
              "label": "Treatment effect"
            },
            {
              "columnId": "Effect_Estimate",
              "label": "Effect estimate"
            },
            {
              "columnId": "Estimate_MarginOfError",
              "label": "Estimate margin of error"
            },
            {
              "columnId": "Control_Value",
              "label": "Control value"
            },
            {
              "columnId": "Treatment_Value",
              "label": "Treatment value"
            },
            {
              "columnId": "Interpretation_Warnings",
              "label": "Interpretability risk",
              "comment": "Detected danger level of misleading metric result, based on insufficient data quality or quantity."
            }
          ]
        },
        "sortBy": []
      },
      "conditionalVisibility": {
        "parameterName": "_control",
        "comparison": "isNotEqualTo"
      },
      "name": "query - metric results"
    },
    {
      "type": 1,
      "content": {
        "json": "> PARAMETER SELECTION REQUIRED\r\n> \r\n> For variant comparison, select your analytics workspace, feature, and control variant."
      },
      "conditionalVisibility": {
        "parameterName": "_control",
        "comparison": "isEqualTo"
      },
      "name": "text - warn no parameters selected"
    }
  ],
  "$schema": "https://github.com/Microsoft/Application-Insights-Workbooks/blob/master/schema/workbook.json"
}
